# -*- coding: utf-8 -*-
"""projek_mlt_rakasatriaefendi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15YdzCt7jGwDhMa5XgnHMd9_db5v1QG7_

# Predictive Analytic: Klasifikasi Penyakit Berdasarkan Gejala Menggunakan Pemodelan Natural Language Processing (NLP)

- **Nama:** Raka Satria Efendi
- **Email:** rakaefendi1683@gmail.comrakaefendi1683@gmail.com
- **USER/ID Dicoding:** rakasatriaefendi

### Rubrik Tambahan - Domain Proyek

* Menguraikan alasan pentingnya permasalahan dan cara penyelesaiannya.
    * **Pentingnya diagnosis awal penyakit dijelaskan dan dikaitkan dengan peran AI berbasis teks sebagai sistem pendukung keputusan.**
* Menyertakan hasil riset atau referensi pendukung.
    * **Telah menyertakan beberapa referensi dari jurnal ilmiah dan arXiv dengan format APA.**

### Rubrik Tambahan - Business Understanding

* Menyediakan dua atau lebih pernyataan solusi, seperti penggunaan lebih dari satu algoritma atau peningkatan model dasar dengan tuning hyperparameter.
    * **Dibandingkan baseline SVM dengan versi tuning Optuna, namun akhirnya diputuskan menggunakan model SVM dengan akurasi 0.98 untuk menghindari overfitting.**
* Solusi yang diajukan harus dapat diukur dengan metrik evaluasi yang sesuai.
    * **Metrik akurasi, precision, recall, F1-score, dan confusion matrix digunakan.**

### Rubrik - Data Understanding

* Melakukan tahapan-tahapan penting untuk memahami data, seperti visualisasi data atau analisis eksploratif (EDA).
    * **Telah dilakukan pemeriksaan jumlah kelas, distribusi label penyakit, serta analisis gejala melalui preprocessing awal.**

### Rubrik - Data Preparation

* Menjelaskan tahapan pemrosesan data yang telah dilakukan.
    * **Melibatkan text cleaning, TF-IDF vectorization, splitting data, dan pengolahan label.**
* Memberikan penjelasan mengenai alasan pentingnya setiap tahapan data preparation.
    * **Telah dijelaskan mengapa TF-IDF dipilih dan bagaimana teks diubah menjadi representasi numerik yang dapat diproses oleh model.**

### Rubrik - Modeling

* Menjelaskan kelebihan dan kelemahan dari setiap algoritma yang digunakan.
    * **SVM dijelaskan sebagai model yang cocok untuk data berdimensi tinggi seperti hasil TF-IDF, serta dipertimbangkan risiko overfitting.**
* Jika hanya menggunakan satu algoritma, maka harus dilakukan peningkatan model melalui hyperparameter tuning. Jelaskan proses tuning-nya.
    * **Hyperparameter tuning dilakukan menggunakan Optuna, namun hasil terbaik (1.00) dianggap overfit dan model 0.98 dipilih.**
* Jika menggunakan lebih dari satu algoritma, harus dipilih model terbaik dan dijelaskan alasan pemilihannya.
    * **Model SVM dipilih karena memberikan keseimbangan antara akurasi dan generalisasi.**

### Rubrik - Evaluation

* Menjelaskan metrik evaluasi yang digunakan untuk mengukur performa model, termasuk rumus dan mekanisme kerja metrik tersebut.
    * **Evaluasi dilakukan dengan confusion matrix, classification report, dan ditambahkan pemaknaan mendalam terhadap hasil klasifikasi per kelas penyakit.**
* Memberikan studi kasus atau prediksi pada data nyata.
    * **Dilakukan pengujian prediksi berdasarkan input gejala diabetes, dan hasilnya sesuai label.**

# Domain Proyek
Di era digital, pasien semakin sering mencari informasi kesehatan melalui internet dengan mengetikkan gejala-gejala yang mereka alami. Namun, tidak semua orang memiliki akses langsung ke tenaga medis, terutama di daerah terpencil. Hal ini dapat menyebabkan keterlambatan dalam penanganan penyakit dan berpotensi memperburuk kondisi kesehatan. Oleh karena itu, diperlukan solusi cerdas yang mampu menganalisis gejala dalam bentuk teks dan memprediksi kemungkinan penyakit secara cepat dan akurat.

Menurut WHO (2023), keterlambatan diagnosis penyakit akibat keterbatasan akses kesehatan menyebabkan peningkatan angka kematian preventable hingga 35% di negara berkembang.

Untuk mengatasi hal ini, dikembangkan sistem klasifikasi penyakit berbasis Natural Language Processing (NLP), yang dapat mengenali pola dari gejala dalam format teks dan menghubungkannya dengan kemungkinan penyakit. Sistem ini menggunakan pendekatan machine learning klasik seperti Logistic Regression dan Naive Bayes, serta dilakukan tuning hyperparameter untuk meningkatkan performa prediksi.

Sistem ini juga dapat dikembangkan lebih lanjut menjadi chatbot medis berbasis AI untuk mendukung self-diagnosis awal dan penyuluhan kesehatan.

# Business Understanding

## Problem Statements

Rumusan masalah dari masalah latar belakang diatas adalah:
1. Bagaimana mengembangkan sistem klasifikasi otomatis untuk memprediksi jenis penyakit berdasarkan input teks berupa gejala?

2. Algoritma machine learning atau NLP apa yang paling efektif dalam melakukan klasifikasi penyakit berbasis gejala tertulis?

3. Seberapa akurat sistem prediksi ini dapat membantu dalam memberikan diagnosis awal berdasarkan gejala?

## GOALS

Berdasarkan problem statements, berikut tujuan yang ingin dicapai pada proyek ini.
1. Membangun sistem klasifikasi penyakit berdasarkan gejala pasien yang tertulis dalam bentuk teks.

2. Mengembangkan dan membandingkan performa beberapa model klasifikasi berbasis NLP, serta memilih model terbaik berdasarkan evaluasi metrik yang sesuai.

3. Menyediakan solusi otomatis dan ringan yang dapat membantu masyarakat maupun tenaga kesehatan dalam mendiagnosis penyakit sejak dini melalui input berbasis teks.

## Solutions Statements

1. Membangun model machine learning berbasis NLP dengan memanfaatkan representasi teks seperti TF-IDF untuk memetakan gejala ke label penyakit, kemudian menganalisis kontribusi kata-kata penting terhadap hasil klasifikasi.

2. Menerapkan dan membandingkan performa dua algoritma klasifikasi yaitu Logistic Regression dan Multinomial Naive Bayes, serta melakukan hyperparameter tuning pada model terbaik untuk meningkatkan akurasi prediksi.

3. Menganalisis konteks semantik dan hubungan antar gejala, dengan mengevaluasi apakah gejala tertentu lebih sering muncul pada penyakit tertentu dan bagaimana pola ini dapat dimanfaatkan oleh model klasifikasi berbasis teks.

## Metodologi

Tujuan yang ingin dicapai dalam proyek ini adalah memprediksi jenis penyakit yang diderita seseorang berdasarkan deskripsi gejala yang diberikan dalam bentuk teks. Metodologi prediktif yang digunakan berfokus pada pembangunan model klasifikasi berbasis Natural Language Processing (NLP), dengan label penyakit sebagai target utama.

## Metrik

Metrik yang digunakan untuk mengevaluasi seberapa baik model klasifikasi merupakan confusion matrix. Confusion matrix merupakan suatu metode yang digunakan untuk melakukan perhitungan akurasi pada konsep data mining. Metrik ini menampilkan jumlah prediksi yang benar dan salah yang dilakukan oleh model klasifikasi, dan dibagi ke dalam empat kategori: True Positive (TP), False Positive (FP), True Negative (TN), dan False Negative (FN).

Dari confusion matrix ini, beberapa metrik turunan dapat dihitung, seperti:

- Accuracy: mengukur persentase prediksi yang benar terhadap total data

- Precision: mengukur ketepatan model dalam memprediksi kelas positif

- Recall: mengukur sejauh mana model dapat menangkap seluruh data positif

- F1-Score: menggabungkan precision dan recall dalam satu nilai harmonik

Penggunaan metrik-metrik ini sangat penting untuk mengevaluasi performa model secara lebih komprehensif, terutama pada dataset yang memiliki distribusi kelas tidak seimbang.

# Data Understanding

Tahap ini merupakan proses analisis data yang bertujuan untuk memperoleh pemahaman yang menyeluruh mengenai dataset sebelum melanjutkan ke tahap analisis lebih lanjut.

## 1. Mengimport Library
"""

pip install kaggle --quiet

!pip install optuna --quiet

# Library dasar
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile
import joblib
import optuna
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Preprocessing teks
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Algoritma klasifikasi
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from xgboost import XGBClassifier

# Pemisahan data dan evaluasi
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay, precision_score, recall_score
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack, csr_matrix
import matplotlib.patches as patches
from matplotlib.patches import ConnectionPatch

"""## Data Loading

tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.
"""

!curl -L -o symptoms.zip\
  "https://www.kaggle.com/api/v1/datasets/download/niyarrbarman/symptom2disease"

# Mengkonversi zip menjadi folder
with zipfile.ZipFile("/content/symptoms.zip", "r") as zip_ref:
    zip_ref.extractall("symptoms")

# Membaca file csv
data = pd.read_csv("/content/symptoms/Symptom2Disease.csv")

# Display the first few rows
data

"""**Insight:**
- Dataset memiliki 1201 baris dan 3 kolom:

- label: kategori penyakit yang menjadi target klasifikasi, seperti Psoriasis, diabetes, dll.

- text: deskripsi gejala dalam bentuk teks yang menjelaskan kondisi pasien.

- Data ini cocok untuk proyek klasifikasi teks penyakit berdasarkan gejala, dengan kolom text sebagai fitur input dan label sebagai target output.

- Dataset mencakup berbagai penyakit dengan jumlah sampel yang relatif besar (1201 data), memungkinkan pelatihan model yang cukup baik untuk prediksi.

### Deskripsi pada variable yang ada

| Variabel   | Keterangan                                                                        | Contoh Jawaban                                       |
| ---------- | --------------------------------------------------------------------------------- | ---------------------------------------------------- |
| Unnamed: 0 | Indeks unik setiap baris data, biasanya hasil ekspor dari CSV                     | 0, 1, 2, ...                                         |
| label      | Kategori penyakit atau diagnosis berdasarkan gejala yang diberikan                | Psoriasis, diabetes, flu, dll.                       |
| text       | Deskripsi gejala berupa teks naratif yang menjelaskan keluhan atau kondisi pasien | "I have been experiencing joint pain in my fingers." |
"""

data.info() # Melihat info apa saja yang ada pada dataset saya

"""**Insight:**
Berikut insight tambahan dari informasi struktur dataset:

* Dataset berisi **1200 entri** tanpa missing values di semua kolom, sehingga data lengkap dan siap untuk analisis.
* Terdiri dari **3 kolom** dengan tipe data:

  * `Unnamed: 0` bertipe **integer** sebagai indeks unik.
  * `label` dan `text` bertipe **object** (string), di mana `label` adalah target klasifikasi dan `text` adalah data teks gejala.
* Ukuran memori dataset relatif kecil (sekitar 28 KB), sehingga proses training model dapat dilakukan dengan efisien pada komputer biasa.
* Data teks bebas dari nilai kosong, memudahkan tahap preprocessing tanpa perlu penanganan missing data khusus.


"""

data.shape  # Melihat bentuk dataset

"""Dari Output diatas dataset saya memiliki informasi:
<br>

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 1200 | 3 |


<br>
"""

# Inisialisasi DataFrame menggunakan data yang tersedia
df_filtered = pd.DataFrame(data)

# Menghasilkan ringkasan statistik untuk memeriksa keberadaan outlier pada data
df_filtered.describe()

"""Fungsi describe() memberikan gambaran statistik dasar untuk kolom Unnamed: 0, yaitu:

* `Count:` Total ada 1200 data (baris) dalam dataset.

* `Mean:` Rata-rata nilai indeks adalah 149,5.

* `Std:` Standar deviasi sebesar 86,64 menunjukkan sebaran nilai indeks yang cukup luas.

* `Min:` Nilai indeks terkecil adalah 0.

* `25%:` Kuartil pertama berada di angka 74,75.

* `50%:` Median (kuartil kedua) tepat di angka 149,5.

* `75%:` Kuartil ketiga berada di angka 224,25.

* `Max:` Nilai indeks terbesar adalah 299.

**Insight:**

- Kolom Unnamed: 0 merepresentasikan indeks atau nomor urut data, sehingga distribusinya harus linier dan teratur dari 0 sampai 299 (maksimal 299) untuk tiap kelompok data jika dataset dibagi menjadi beberapa subset.

- Nilai mean dan median yang sama (149,5) menandakan data terdistribusi secara simetris dalam kolom indeks.

- Standar deviasi yang cukup besar (86,64) sesuai dengan rentang nilai indeks yang luas dari 0 hingga 299.

- Kuartil menunjukkan pembagian data indeks ke dalam empat bagian yang seimbang, yang juga mengonfirmasi indeks ini terdistribusi merata.

- Karena ini hanya indeks, informasi ini lebih mengkonfirmasi kelengkapan dan konsistensi data, bukan informasi isi variabel fitur.

## Exploratory Data Analysis - Univariate Analysis
( analisis yang hanya melihat satu variabel saja dalam data. analisis yang hanya melihat satu variabel saja dalam data.)
"""

# Variabel fitur berdasarkan dataset symptoms
categorical_feature = ['label']
text_feature = ['text']

"""### Categorical Features"""

# Visualisasi distribusi label (kategori penyakit)
plt.figure(figsize=(12,7))
label_counts = data['label'].value_counts()
sns.barplot(x=label_counts.values, y=label_counts.index, palette='coolwarm')
plt.title('Distribusi Kategori Penyakit (Label)')
plt.xlabel('Jumlah Data')
plt.ylabel('Penyakit')
plt.show()

"""1. Interpretasi Umum: Grafik ini menunjukkan frekuensi atau jumlah data yang sama untuk setiap kategori penyakit yang terdaftar. Hampir semua penyakit memiliki jumlah data sekitar 50, menunjukkan kemungkinan bahwa dataset ini memiliki jumlah sampel yang seimbang untuk setiap kategori penyakit, atau mungkin ini adalah hasil dari oversampling atau undersampling untuk menyeimbangkan kelas.

2. Penyakit dengan Jumlah Data Terbanyak: Penyakit seperti `diabetes`, `peptic ulcer disease`, `drug reaction`, dan `gastroesophageal reflux disease` berada di bagian bawah grafik dan diwakili dengan warna merah tua, namun jumlah datanya juga sekitar 50, sama dengan penyakit lain di kategori lain.

3. Penyakit dengan Jumlah Data Terendah: Tidak ada penyakit yang memiliki jumlah data yang signifikan lebih rendah dari yang lain. Semua kategori penyakit, dari `Psoriasis` hingga `diabetes`, memiliki jumlah data yang seragam, yaitu sekitar 50.

4. Distribusi Seragam: Poin paling penting dari grafik ini adalah distribusi yang sangat seragam di antara semua kategori penyakit. Ini menunjukkan bahwa setiap penyakit memiliki representasi yang hampir sama dalam dataset. Ini bisa menjadi karakteristik dari dataset yang seimbang, yang penting untuk pelatihan model machine learning agar tidak bias terhadap kelas mayoritas.

### Text Features
"""

# Menghitung panjang teks
data['text_length'] = data['text'].apply(len)

# Visualisasi distribusi panjang teks
plt.figure(figsize=(10,4))
sns.histplot(data['text_length'], bins=30, kde=True)
plt.title('Distribusi Panjang Teks')
plt.xlabel('Panjang Teks (karakter)')
plt.ylabel('Frekuensi')
plt.show()

"""Interpretasi Grafik "Distribusi Panjang Teks"

Gambar di atas adalah sebuah histogram yang memvisualisasikan distribusi panjang teks dalam karakter, dilengkapi dengan kurva estimasi kepadatan kernel (KDE) yang menampilkan bentuk distribusi data.

Berikut adalah interpretasi dari grafik tersebut:

1.  **Judul dan Sumbu Grafik**:
    * **Judul (`Distribusi Panjang Teks`)**: Menunjukkan bahwa grafik ini menggambarkan bagaimana panjang teks didistribusikan dalam dataset yang sedang dianalisis.
    * **Sumbu X (`Panjang Teks (karakter)`)**: Merepresentasikan panjang setiap teks, diukur dalam jumlah karakter.
    * **Sumbu Y (`Frekuensi`)**: Menunjukkan berapa banyak teks yang termasuk dalam rentang panjang karakter tertentu (yang diwakili oleh setiap batang histogram).

2.  **Bentuk Distribusi Data**:
    * Distribusi panjang teks ini terlihat **mendekati distribusi normal** (atau sedikit miring/skewed). Hal ini ditunjukkan oleh bentuk kurva KDE (garis biru) yang menyerupai lonceng, meskipun puncaknya tidak sepenuhnya simetris sempurna.
    * Grafik ini menunjukkan **satu puncak yang dominan (unimodal)**.

3.  **Nilai Pusat Distribusi**:
    * **Puncak distribusi (modus)** atau konsentrasi terbesar teks berada pada rentang **sekitar 150 hingga 170 karakter**. Ini mengindikasikan bahwa sebagian besar teks dalam dataset memiliki panjang di kisaran ini.
    * Pada rentang ini, frekuensi teks mencapai nilai tertinggi, yaitu lebih dari 140.

4.  **Sebaran dan Variabilitas Data**:
    * Panjang teks dalam dataset bervariasi luas, mulai dari sekitar 50 karakter hingga lebih dari 300 karakter.
    * Meskipun ada beberapa teks yang sangat pendek (sekitar 50-100 karakter) dan beberapa yang sangat panjang (sekitar 250-300 karakter), frekuensi kemunculannya jauh lebih rendah dibandingkan dengan teks yang memiliki panjang di sekitar nilai pusat.
    * Distribusi ini menunjukkan bahwa sebagian besar data (teks) terkonsentrasi di sekitar nilai rata-rata, dan frekuensi kemunculan teks secara bertahap menurun saat panjang teks semakin menjauh dari pusat.

5.  **Anomali atau Outlier**:
    * Secara visual, tidak ada anomali atau *outlier* yang sangat ekstrem dan mencolok. Meskipun ada teks dengan panjang yang relatif rendah atau tinggi, jumlahnya sangat kecil sehingga tidak menunjukkan adanya masalah data yang signifikan atau observasi yang sangat tidak biasa.

**Kesimpulan**:

Secara keseluruhan, grafik ini menunjukkan bahwa panjang teks dalam dataset memiliki distribusi yang cukup terpusat di sekitar 150-170 karakter. Mayoritas teks memiliki panjang antara 100 hingga 220 karakter, dengan frekuensi yang berkurang di kedua ujung distribusi. Distribusi ini relatif simetris dan menunjukkan karakteristik yang menyerupai distribusi normal.
"""

# Membuat word cloud
text_combined = " ".join(data['text'].tolist())
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_combined)

plt.figure(figsize=(12,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud dari Text')
plt.show()

"""interpretasi dari word cloud tersebut:

1.  **Kata Kunci Dominan (Kata Terbesar)**:
    * Kata-kata seperti "**experiencing**", "**pain**", "**skin**", "**feeling**", "**cough**", "**fever**", "**throat**", "**headache**", "**difficult**", dan "**additonal**" muncul dengan ukuran font yang paling besar. Ini menunjukkan bahwa kata-kata ini adalah yang paling sering muncul atau paling relevan dalam kumpulan teks yang dianalisis. Kata-kata ini kemungkinan besar adalah gejala atau kondisi medis utama yang dibahas dalam data teks.

2.  **Kata Kunci Penting Lainnya (Ukuran Sedang)**:
    * Kata-kata dengan ukuran sedang seperti "**swelling**", "**nausea**", "**vomiting**", "**body**", "**back pain**", "**rash**", "**joint**", "**mild**", "**sore**", "**heart**", "**stomach**", "**tired**", "**weak**", "**breathing**", "**chest**", "**time**", "**recently**", "**frequent**", "**burning**", "**itching**", dan "**red**" juga sering muncul, mengindikasikan gejala atau karakteristik tambahan yang terkait dengan kondisi utama.

3.  **Kata Kunci Pendukung (Ukuran Kecil)**:
    * Kata-kata yang lebih kecil seperti "**arm**", "**become**", "**uncomfortable**", "**calves**", "**spots**", "**symptoms**", "**nose**", "**muscle**", "**trouble**", "**mucus**", "**well**", "**dark**", "**bumpy**", "**concentrate**", "**causing**", "**chills**", "**perspiring**", "**urination**", "**urine**", "**neck**", "**fatigue**", "**mouth**", "**pus**", "**phlegm**", "**eating**", "**drinking**", "**sleep**", "**dizzy**", "**extreme**", "**visual disturbance**", "**constipation**", "**sensitive**", "**develop**", "**inflamed**", "**unsteady**", "**balance**", "**smell**", "**appetite**", dll. menunjukkan detail, lokasi, atau deskripsi yang lebih spesifik mengenai gejala-gejala yang lebih besar.

4.  **Tema Umum**:
    * Secara keseluruhan, word cloud ini sangat terfokus pada **gejala-gejala medis dan keluhan fisik**. Kata-kata dominan secara jelas menunjukkan fokus pada pengalaman rasa sakit, kondisi kulit, sensasi umum, dan masalah pernapasan/tenggorokan. Ini mengindikasikan bahwa data teks kemungkinan besar berasal dari catatan medis, laporan pasien, atau deskripsi keluhan kesehatan.

5.  **Implikasi**:
    * Jika data ini digunakan untuk tujuan diagnostik atau analisis kesehatan, kata kunci yang dominan ini akan menjadi titik fokus utama untuk mengidentifikasi pola penyakit atau keluhan yang paling umum di antara populasi yang datanya dianalisis.

**Kesimpulan**:

Word cloud ini secara efektif memvisualisasikan frekuensi kata-kata dalam data teks, dengan jelas menyoroti bahwa **gejala-gejala fisik dan rasa sakit (seperti "pain", "skin", "fever", "cough", "headache")** adalah topik atau keluhan yang paling sering muncul dan dominan dalam kumpulan teks yang dianalisis. Ini memberikan gambaran cepat tentang isi utama dari data teks tersebut yang sangat relevan dengan domain kesehatan atau medis.
"""

# Barplot 20 kata terbanyak (stopwords bisa dihapus jika ingin)
words = " ".join(data['text']).lower().split()
word_counts = Counter(words)
most_common_words = word_counts.most_common(20)

words_bar = [w[0] for w in most_common_words]
counts_bar = [w[1] for w in most_common_words]

plt.figure(figsize=(12,6))
sns.barplot(x=counts_bar, y=words_bar, palette='viridis')
plt.title('20 Kata Terbanyak dalam Text')
plt.xlabel('Frekuensi')
plt.ylabel('Kata')
plt.show()

"""Interpretasi Grafik "20 Kata Terbanyak dalam Text"

Gambar di atas menampilkan sebuah grafik batang horizontal yang menunjukkan 20 kata yang paling sering muncul (terbanyak) dalam sebuah kumpulan teks. Sumbu X merepresentasikan "Frekuensi" (berapa kali kata tersebut muncul), dan sumbu Y merepresentasikan "Kata" itu sendiri. Warna batang bervariasi menggunakan palet 'viridis', yang secara visual dapat membantu membedakan atau mengelompokkan kata-kata meskipun tidak ada makna khusus terkait urutan warna di sini selain sebagai pembeda.

Berikut adalah interpretasi dari grafik batang ini:

1.  **Judul dan Sumbu Grafik**:
    * **Judul (`20 Kata Terbanyak dalam Text`)**: Menjelaskan tujuan grafik, yaitu untuk mengidentifikasi kata-kata yang paling sering digunakan dalam dataset teks.
    * **Sumbu X (`Frekuensi`)**: Menunjukkan jumlah kemunculan (count) dari setiap kata.
    * **Sumbu Y (`Kata`)**: Mendaftar kata-kata yang dianalisis, diurutkan dari frekuensi tertinggi di atas hingga terendah di bawah.

2.  **Kata-kata dengan Frekuensi Tertinggi**:
    * Kata-kata seperti "**and**", "**my**", "**i**", "**a**", "**been**", dan "**have**" memiliki frekuensi kemunculan tertinggi, dengan frekuensi tertinggi mencapai lebih dari 2500 untuk kata "and".
    * Ini menunjukkan bahwa kata-kata ini adalah kata-kata fungsional (seperti konjungsi, kata ganti, artikel, atau kata kerja bantu) yang sangat umum dalam bahasa Inggris, dan sering kali tidak memiliki makna konten yang kuat dalam analisis teks, melainkan lebih berfungsi sebagai "stop words".

3.  **Distribusi Frekuensi Kata**:
    * Terlihat jelas ada perbedaan frekuensi yang signifikan antara kata-kata teratas dan kata-kata di bagian bawah daftar 20 teratas. Misalnya, "and" muncul lebih dari 2500 kali, sementara "with" muncul kurang dari 250 kali.
    * Frekuensi kata-kata cenderung menurun secara bertahap dari atas ke bawah, sesuai dengan urutan pengurutan.

4.  **Jenis Kata yang Dominan**:
    * Mayoritas dari 20 kata terbanyak ini adalah **kata-kata penghubung, artikel, preposisi, atau kata ganti** (misalnya, "and", "my", "i", "a", "been", "have", "of", "to", "the", "in", "is", "has", "are"). Ini adalah karakteristik umum dalam analisis frekuensi kata pada sebagian besar dataset teks, terutama jika "stop words" belum dihapus.
    * Namun, ada juga beberapa kata bermakna atau kata kunci yang mulai muncul di bagian bawah daftar ini, seperti "skin" dan "on" (meskipun "on" juga bisa menjadi preposisi), yang mungkin relevan dengan topik teks jika "stop words" telah dihapus secara sebagian atau jika topik teks sangat spesifik.

5.  **Implikasi untuk Analisis Teks**:
    * Jika tujuan analisis adalah untuk memahami topik atau konten substantif dari teks, kata-kata yang paling sering muncul ini (terutama "stop words") seringkali perlu **dihilangkan (difilter)**.
    * Setelah stop words dihilangkan, grafik ini dapat dibuat ulang untuk menunjukkan kata-kata yang benar-benar relevan dengan isi atau tema utama teks, seperti gejala penyakit, kondisi, atau kata kunci domain spesifik lainnya.

**Kesimpulan**:

Grafik ini secara efektif menunjukkan frekuensi kemunculan 20 kata teratas dalam dataset teks. Dominasi kata-kata fungsional (seperti "and", "my", "i") menunjukkan bahwa dataset ini mungkin masih mengandung "stop words". Untuk analisis konten yang lebih mendalam, langkah pra-pemrosesan seperti penghapusan stop words akan sangat bermanfaat untuk menyoroti kata-kata yang lebih bermakna dan relevan dengan topik teks.

## Exploratory Data Analysis - Multivariate Analysis

### Distribusi Panjang Gejala (Text Length) per Kategori Penyakit
"""

# Menambahkan kolom baru untuk panjang karakter setiap gejala
data['text_length'] = data['text'].apply(len)

# Visualisasi panjang gejala berdasarkan label
plt.figure(figsize=(20,6))
sns.boxplot(data=data, x='label', y='text_length', palette='Set2')
plt.title('Distribusi Panjang Gejala berdasarkan Kategori Penyakit')
plt.xlabel('Penyakit')
plt.ylabel('Jumlah Karakter pada Gejala')
plt.xticks(rotation=45)
plt.show()

"""**Insight:**

Visualisasi di atas menyajikan distribusi panjang gejala (jumlah karakter pada gejala) untuk berbagai kategori penyakit. Dari *boxplot* ini, kita bisa mendapatkan beberapa *insight* menarik:

## Penyakit dengan Panjang Gejala Cenderung Lebih Tinggi:

* **Infeksi Jamur (Fungal Infection), Pneumonia, dan Batuk Pilek Biasa (Common Cold):** Penyakit-penyakit ini menunjukkan median panjang gejala yang relatif tinggi, seringkali di atas 200 karakter. Kotak *boxplot* mereka juga cenderung berada di bagian atas grafik, mengindikasikan bahwa sebagian besar gejala untuk penyakit-penyakit ini dijelaskan dengan lebih banyak detail atau memiliki deskripsi yang lebih panjang.
* **Asma Bronkial (Bronchial Asthma) dan Migrain:** Meskipun mediannya tidak setinggi grup sebelumnya, rentang interkuartil (IQR) untuk Asma Bronkial menunjukkan variasi yang cukup besar dengan beberapa gejala yang sangat panjang (di atas 250 karakter). Migrain juga memiliki median yang cukup tinggi, mendekati 200 karakter.

## Penyakit dengan Panjang Gejala Cenderung Lebih Rendah:

* **Varises (Varicose Veins), Tifoid (Typhoid), dan Cacar Air (Chicken Pox):** Penyakit-penyakit ini memiliki median panjang gejala yang cenderung lebih rendah, seringkali di bawah 150 karakter. Ini menunjukkan bahwa gejala-gejala yang terkait dengan penyakit-penyakit ini mungkin dijelaskan dengan lebih ringkas atau deskripsi gejalanya lebih pendek.
* **Tekanan Darah Tinggi (Hypertension) dan Hepatitis Kuning (Jaundice):** Kedua penyakit ini juga menunjukkan median panjang gejala yang relatif rendah, dengan sebagian besar data berada di bawah 175 karakter.

## Variabilitas Panjang Gejala:

* **Asma Bronkial (Bronchial Asthma):** Menunjukkan rentang *boxplot* yang sangat lebar, menandakan variasi yang signifikan dalam panjang gejala. Ada beberapa *outlier* yang menunjukkan gejala yang sangat panjang (di atas 300 karakter), serta beberapa gejala yang relatif pendek.
* **Psoriasis dan Diabetes:** Memiliki rentang *boxplot* yang cukup sempit, menunjukkan bahwa panjang gejala untuk penyakit-penyakit ini cenderung konsisten dan tidak terlalu bervariasi.
* **Beberapa *outlier* terlihat di berbagai penyakit**, seperti pada "Impetigo" (gejala yang sangat pendek) dan "Alergi" (gejala yang sangat pendek). *Outlier* ini bisa jadi merupakan data anomali atau menunjukkan adanya variasi unik dalam cara gejala-gejala tertentu dideskripsikan.

## Implikasi Potensial:

* **Pembersihan Data (Data Cleaning):** Adanya *outlier* yang sangat rendah atau sangat tinggi mungkin memerlukan investigasi lebih lanjut. Apakah ada kesalahan entri data, atau memang ada gejala yang dideskripsikan secara sangat ringkas atau sangat detail?
* **Analisis Teks Lanjutan:** Penyakit dengan panjang gejala yang lebih tinggi mungkin memerlukan metode pemrosesan bahasa alami (NLP) yang lebih canggih untuk mengekstraksi informasi kunci dari deskripsi gejala yang panjang.
* **Prediksi Penyakit:** Panjang gejala itu sendiri mungkin bisa menjadi fitur prediktif dalam model *machine learning*. Misalnya, jika suatu deskripsi gejala sangat pendek, mungkin cenderung mengarah pada penyakit tertentu.
* **Perbandingan Deskripsi Klinis:** Visualisasi ini dapat mengindikasikan perbedaan dalam standar atau kebiasaan deskripsi gejala antar penyakit. Beberapa penyakit mungkin memiliki definisi gejala yang lebih baku dan ringkas, sementara yang lain memerlukan penjelasan yang lebih mendalam.

Secara keseluruhan, visualisasi ini memberikan gambaran awal tentang karakteristik data tekstual gejala penyakit, menyoroti perbedaan dan variabilitas yang ada, yang dapat memandu langkah-langkah pra-pemrosesan data dan analisis selanjutnya.

### Distribusi Jumlah Kata (Token Count) per Label
"""

# Menambahkan kolom baru untuk menghitung jumlah kata
data['word_count'] = data['text'].apply(lambda x: len(str(x).split()))

# Visualisasi jumlah kata berdasarkan label
plt.figure(figsize=(20,6))
sns.violinplot(data=data, x='label', y='word_count', palette='muted')
plt.title('Distribusi Jumlah Kata Gejala berdasarkan Kategori Penyakit')
plt.xlabel('Penyakit')
plt.ylabel('Jumlah Kata pada Gejala')
plt.xticks(rotation=45)
plt.show()

"""**Insight**

Visualisasi *violin plot* di atas menampilkan distribusi jumlah kata pada gejala untuk berbagai kategori penyakit. Ini memberikan gambaran yang lebih detail mengenai kepadatan distribusi data dibandingkan *boxplot* saja.

## Penyakit dengan Jumlah Kata Gejala Cenderung Lebih Tinggi:

* **Infeksi Jamur (Fungal Infection), Batuk Pilek Biasa (Common Cold), Pneumonia, dan Asma Bronkial (Bronchial Asthma):** Penyakit-penyakit ini menunjukkan distribusi dengan puncak kepadatan (median) di sekitar 40-50 kata. Bentuk *violin* untuk "Asma Bronkial" secara khusus sangat tinggi dan melebar di bagian atas, menunjukkan bahwa gejala untuk penyakit ini seringkali dideskripsikan dengan jumlah kata yang lebih banyak, bahkan ada yang mencapai lebih dari 60 kata.

## Penyakit dengan Jumlah Kata Gejala Cenderung Lebih Rendah:

* **Varises (Varicose Veins), Tifoid (Typhoid), Cacar Air (Chicken Pox), Impetigo, Tekanan Darah Tinggi (Hypertension), Migrain, dan Hepatitis Kuning (Jaundice):** Kategori penyakit ini umumnya memiliki distribusi jumlah kata gejala yang lebih rendah, dengan puncak kepadatan (median) berkisar antara 20 hingga 30 kata. Bentuk *violin* untuk "Migrain" sangat ramping di bagian tengah dan melebar di bagian bawah, menunjukkan bahwa sebagian besar gejala migrain dijelaskan dengan jumlah kata yang lebih sedikit, meskipun ada beberapa yang sedikit lebih panjang.

## Variabilitas dan Bentuk Distribusi:

* **Asma Bronkial (Bronchial Asthma):** Menunjukkan distribusi yang paling lebar dan paling tinggi di antara semua kategori, mengindikasikan variasi yang sangat besar dalam jumlah kata gejala, dari yang sangat sedikit hingga sangat banyak (lebih dari 60 kata). Bentuk *violin* yang memanjang ke atas juga menunjukkan adanya sejumlah besar gejala yang dideskripsikan dengan sangat rinci.
* **Migrain:** Memiliki bentuk *violin* yang unik, sangat ramping di bagian tengah dan melebar di bagian bawah, dengan ekor yang panjang ke atas. Ini menunjukkan bahwa meskipun sebagian besar gejala migrain dijelaskan dengan kata yang relatif sedikit, ada juga beberapa kasus di mana deskripsinya bisa sangat panjang.
* **Penyakit dengan Distribusi Simetris (Kurang Lebih):** Psoriasis, Diare (Dengue), Radang Sendi (Arthritis), Alergi (Allergy), dan Diabetes menunjukkan bentuk *violin* yang relatif lebih simetris di sekitar mediannya, mengindikasikan distribusi jumlah kata yang lebih merata di sekitar nilai tengah.
* **Penyakit dengan Distribusi Condong ke Kanan (Right-skewed):** Beberapa penyakit seperti "Tekanan Darah Tinggi (Hypertension)" dan "Hepatitis Kuning (Jaundice)" tampak sedikit condong ke kanan, menunjukkan bahwa meskipun sebagian besar gejalanya pendek, ada beberapa gejala yang lebih panjang.

## Implikasi Potensial:

* **Pembersihan dan Normalisasi Teks:** Penyakit dengan variasi jumlah kata yang tinggi (misalnya, Asma Bronkial) mungkin memerlukan teknik normalisasi teks yang lebih canggih untuk memastikan representasi yang konsisten untuk analisis lebih lanjut.
* **Ekstraksi Fitur:** Jumlah kata per gejala itu sendiri bisa menjadi fitur yang berguna dalam model *machine learning* untuk klasifikasi penyakit. Penyakit dengan jumlah kata yang lebih tinggi mungkin mengindikasikan kompleksitas deskripsi gejala yang lebih besar.
* **Analisis Semantik:** Untuk penyakit dengan jumlah kata yang tinggi, analisis semantik (misalnya, *topic modeling* atau ekstraksi entitas) mungkin lebih relevan untuk menemukan pola dalam deskripsi yang lebih panjang.
* **Desain Kuesioner/Survei:** *Insight* ini dapat membantu dalam merancang kuesioner atau sistem pelaporan gejala yang lebih efektif, mempertimbangkan rata-rata dan variasi panjang deskripsi yang diharapkan.

Secara keseluruhan, *violin plot* ini memberikan pemahaman yang lebih dalam tentang karakteristik data tekstual gejala, menunjukkan tidak hanya rata-rata jumlah kata tetapi juga kepadatan dan bentuk distribusinya, yang krusial untuk langkah-langkah pra-pemrosesan dan pemodelan data yang efektif.

## Data Quality Verification

### Memeriksa Data duplikat
"""

# Cek jumlah data duplikat
duplicate_rows = data.duplicated()
jumlah_duplikat = duplicate_rows.sum()

print(f"Jumlah data duplikat: {jumlah_duplikat}")

# Menampilkan baris duplikat (jika ada)
if jumlah_duplikat > 0:
    display(data[duplicate_rows])
else:
    print("Tidak ada data duplikat yang ditemukan.")

"""**Insight:**

Terdapat 0 data duplikat

### Memeriksa data null
"""

data.isnull().sum()

"""Terdapat 0 data null

### Cek apakah kolom numerik `Unnamed : 0` diperlukan

#### 1. Tampilkan 10 data awal dari kolom 'Unnamed: 0'
"""

print("Isi 10 data awal kolom 'Unnamed: 0':")
print(data['Unnamed: 0'].head(10))

"""#### 2. Cek jumlah nilai unik di kolom 'Unnamed: 0'"""

unique_count = data['Unnamed: 0'].nunique()
total_rows = data.shape[0]
print(f"\nJumlah nilai unik di 'Unnamed: 0': {unique_count}")
print(f"Jumlah total baris data: {total_rows}")

"""#### 3. Cek apakah nilai kolom 'Unnamed: 0' sama persis dengan index DataFrame"""

is_same_as_index = (data['Unnamed: 0'] == data.index).all()
print(f"\nApakah 'Unnamed: 0' identik dengan index DataFrame? {is_same_as_index}")

"""#### 4. Insight dan keputusan berdasarkan pengecekan"""

if is_same_as_index:
    print("\nInsight:")
    print("- Kolom 'Unnamed: 0' hanya mereplikasi index DataFrame, sehingga tidak memberikan informasi tambahan.")
    print("- Disarankan untuk menghapus kolom ini agar data lebih bersih dan efisien.")
    # Menghapus kolom
    data = data.drop(columns=['Unnamed: 0'])
    print("Kolom 'Unnamed: 0' telah dihapus.")
else:
    print("\nInsight:")
    print("- Kolom 'Unnamed: 0' tidak identik dengan index DataFrame.")
    print(f"- Jumlah nilai unik hanya {unique_count}, sedangkan jumlah baris ada {total_rows}.")
    print("- Ini menandakan terdapat nilai yang berulang di kolom ini.")
    print("- Jika kolom ini bukan ID unik atau fitur penting lain, maka sebaiknya kolom ini juga dihapus untuk menghindari kebingungan.")
    data = data.drop(columns=['Unnamed: 0'])
    print("- Kolom 'Unnamed: 0' telah dihapus.")

print(data.head())

"""### Cek Missing Value pada Kolom Kategorikal (label)"""

# Cek jumlah NaN asli
print("Jumlah NaN asli pada kolom kategorikal:")
print(data[['label']].isna().sum())
print("================================================")

# Cek string kosong atau spasi
print("Jumlah string kosong atau spasi:")
print(data['label'].isin(["", " "]).sum())
print("================================================")

# Cek string umum yang bermakna missing
print("Jumlah 'NA' atau 'null' atau 'nan' string:")
print(data['label'].isin(["NA", "null", "nan"]).sum())

"""### Cek Missing Value pada Kolom Teks (text)"""

# Cek jumlah NaN asli
print("Jumlah NaN asli pada kolom teks:")
print(data[['text']].isna().sum())
print("================================================")

# Cek string kosong atau spasi
print("Jumlah string kosong atau spasi:")
print(data['text'].isin(["", " "]).sum())
print("================================================")

# Cek string umum yang bermakna missing
print("Jumlah 'NA' atau 'null' atau 'nan' string:")
print(data['text'].isin(["NA", "null", "nan"]).sum())

"""### Memeriksa Data Outlier"""

data.describe()

"""**Insight Statistik Deskriptif:**

Fungsi `describe()` memberikan gambaran statistik ringkas untuk dua fitur numerik, yaitu `text_length` dan `word_count`. Berikut penjelasannya:

* **Count**
  Jumlah total data yang tersedia untuk masing-masing fitur adalah 1200 sampel, yang menunjukkan tidak ada data kosong (missing value) pada kedua kolom ini.

* **Mean (Rata-rata)**

  * `text_length`: Rata-rata panjang teks adalah sekitar 172 karakter.
  * `word_count`: Rata-rata jumlah kata per teks adalah sekitar 30,7 kata.

* **Std (Standar deviasi)**

  * `text_length`: Standar deviasi sebesar 35,5 menunjukkan adanya variasi yang cukup signifikan dalam panjang teks antar sampel.
  * `word_count`: Standar deviasi 6,7 juga menunjukkan variasi jumlah kata yang cukup besar antar teks.

* **Min (Nilai minimum)**

  * `text_length`: Panjang teks terpendek adalah 60 karakter.
  * `word_count`: Jumlah kata terkecil dalam teks adalah 12 kata.

* **Kuartil (25%, 50%, 75%)**

  * Kuartil pertama (`25%`): 147,75 karakter dan 26 kata, berarti 25% data memiliki nilai di bawah ini.
  * Median (`50%`): 170 karakter dan 30 kata, menunjukkan nilai tengah data.
  * Kuartil ketiga (`75%`): 193 karakter dan 35 kata, artinya 75% data memiliki nilai kurang dari ini.

* **Max (Nilai maksimum)**

  * `text_length`: Panjang teks terpanjang mencapai 317 karakter, lebih dari dua kali standar deviasi dari rata-rata, yang menunjukkan ada beberapa teks yang jauh lebih panjang.
  * `word_count`: Jumlah kata terbanyak adalah 55 kata.

**Temuan Penting:**
* Terdapat kemungkinan outlier pada nilai minimum dan maksimum untuk fitur text_length (60 dan 317 karakter) yang berada di luar rentang interkuartil yang wajar.

* Fitur word_count juga menunjukkan potensi outlier pada nilai minimum (12 kata) dan maksimum (55 kata) yang cukup ekstrem jika dibandingkan dengan nilai rata-rata dan kuartilnya.

* Outlier ini perlu dianalisis lebih lanjut untuk memastikan apakah data tersebut valid atau perlu penanganan khusus.
"""

def cek_outlier(df, kolom):
    """
    Fungsi ini akan mencari outlier pada kolom tertentu menggunakan metode IQR (Interquartile Range).
    Outlier adalah nilai yang jauh berbeda dari nilai lainnya, bisa sangat kecil atau sangat besar.
    """
    Q1 = df[kolom].quantile(0.25)  # Kuartil pertama (nilai batas bawah)
    Q3 = df[kolom].quantile(0.75)  # Kuartil ketiga (nilai batas atas)
    IQR = Q3 - Q1  # Jarak antar kuartil

    batas_bawah = Q1 - 1.5 * IQR
    batas_atas = Q3 + 1.5 * IQR

    # Cari nilai yang di luar batas ini dianggap outlier
    outlier = df[(df[kolom] < batas_bawah) | (df[kolom] > batas_atas)][kolom]

    print(f"Outlier pada kolom '{kolom}':")
    if outlier.empty:
        print("Tidak ditemukan outlier.")
    else:
        print(outlier.to_list())
        print(f"Total outlier: {len(outlier)}")
    print("-" * 40)

# Contoh panggil fungsi untuk tiap fitur numerik
numerical_feature = ['text_length', 'word_count']
for fitur in numerical_feature:
    cek_outlier(data, fitur)

# Buat grid 2x2 (karena hanya 2 fitur numerik, sesuaikan jika lebih)
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))
fig.suptitle('Boxplot of Numerical Features', fontsize=16)

# Flatten axes supaya bisa di-loop (meski di sini sudah 1 dimensi)
axes = axes.flatten()

# Loop fitur dan plot
for i, feature in enumerate(numerical_feature):
    sns.boxplot(data=data, x=feature, ax=axes[i], color='skyblue')
    axes[i].set_title(f'{feature}')
    axes[i].set_xlabel('')

plt.tight_layout(rect=[0, 0, 1, 0.95])  # Agar tidak ketimpa judul
plt.show()

"""**Berikut adalah interpretasi dari boxplot di atas.**
1. Pada kolom `text_length`, mayoritas panjang teks (gejala) berada di rentang sekitar 150 hingga 200 karakter. Terdapat sejumlah *outlier* pada kedua sisi distribusi, yaitu teks dengan panjang di bawah sekitar 70 karakter dan di atas sekitar 250 karakter. Meskipun demikian, *outlier* ini tidak akan dihapus karena sangat memungkinkan adanya deskripsi gejala yang sangat ringkas atau sangat detail, tergantung pada kompleksitas gejala atau kebiasaan penulisan.
2. Pada kolom `word_count`, dapat dilihat bahwa mayoritas jumlah kata pada gejala berada di rentang sekitar 25 hingga 35 kata. Mirip dengan `text_length`, terdapat juga *outlier* pada kedua sisi, yaitu jumlah kata di bawah sekitar 15 kata dan di atas sekitar 45 kata. *Outlier* ini juga tidak akan dihapus karena representasi jumlah kata yang ekstrem sangat mungkin terjadi dalam deskripsi gejala, misalnya gejala yang hanya terdiri dari beberapa kata kunci atau gejala yang dijelaskan dengan kalimat yang sangat panjang.

**Kesimpulan:**

Dari hasil analisis statistik deskriptif pada fitur `text_length` dan `word_count`, dapat disimpulkan bahwa kedua fitur menunjukkan keberadaan nilai yang tergolong ekstrem (outlier) namun masih valid secara kontekstual dalam konteks deskripsi gejala. Oleh karena itu, nilai-nilai tersebut tidak dihapus dari *dataset* karena tetap relevan untuk analisis lebih lanjut terkait karakteristik tekstual gejala penyakit. Distribusi data secara umum menunjukkan bahwa sebagian besar gejala memiliki panjang dan jumlah kata dalam rentang yang wajar, namun variasi yang ada perlu dipertimbangkan dalam tahap pra-pemrosesan data selanjutnya.

# Data Preparation

## Menangani Missing Value
"""

# List nilai yang dianggap missing tapi bukan np.nan
missing_vals = ["", " ", "NA", "N/A", "null", "nan", None]

# Ganti nilai tersebut jadi np.nan di kolom kategorikal
data[categorical_feature] = data[categorical_feature].replace(missing_vals, np.nan)

# Cek kembali jumlah NaN setelah replace
print("Jumlah NaN setelah replace di kolom kategorikal:")
print(data[categorical_feature].isna().sum())

data.shape

"""**Insight:**
1. Total data tetap karena tidak ada missing vaalue yang perlu dihapus
"""

print(data.dtypes)

"""## Label Encoding"""

# Inisialisasi encoder
le = LabelEncoder()

# Transform kolom label
data['label_encoded'] = le.fit_transform(data['label'])

# (Opsional) Lihat mapping label ke angka
label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("Mapping Label:", label_mapping)

"""**Insight dari Label Encoding Kategori Penyakit:**

* Mapping Label memperlihatkan bahwa dataset memiliki 24 kelas unik penyakit yang sudah dikonversi menjadi angka dari 0 sampai 23.

* Label numerik ini berfungsi sebagai representasi yang dapat diproses model machine learning untuk klasifikasi multi-kelas.

* Penyakit seperti Acne, Arthritis, Bronchial Asthma, dan Cervical spondylosis masing-masing diberi kode unik, misalnya Acne = 0, Arthritis = 1, dan seterusnya.

* Tidak ada urutan atau bobot inheren pada angka tersebut karena Label Encoding hanya mengubah kategori menjadi angka, bukan memberikan nilai kuantitatif.

* Dengan encoding ini, model dapat belajar membedakan tiap penyakit berdasarkan fitur yang diberikan, selama target label disiapkan sebagai integer.
"""

# Cek distribusi label setelah encoding
label_counts = data['label_encoded'].value_counts().sort_index()

print("Distribusi jumlah data per label (encoded):")
print(label_counts)

# Visualisasi distribusi label
plt.figure(figsize=(12,6))
sns.barplot(x=label_counts.index, y=label_counts.values, palette='viridis')
plt.title('Distribusi Data per Label (Encoded)')
plt.xlabel('Label Encoded')
plt.ylabel('Jumlah Data')
plt.show()

"""## TF-IDF"""

# Inisialisasi TF-IDF vectorizer
tfidf = TfidfVectorizer(max_features=1000)

# Transform teks menjadi vektor TF-IDF

tfidf_vectorizer = TfidfVectorizer(max_features=1000)
X_tfidf = tfidf_vectorizer.fit_transform(data['text'])  # vectorizer disimpan

# X_tfidf adalah matriks sparse (bisa digunakan langsung di model ML)
print(X_tfidf.shape)  # Contoh: (jumlah_data, 1000 fitur)

"""**Insight Hasil TF-IDF:**

* Dataset memiliki 1200 dokumen (baris) yang masing-masing direpresentasikan dalam bentuk vektor fitur.

* Setiap dokumen diwakili oleh 1000 fitur unik (kolom) yang merupakan kata atau token setelah proses ekstraksi TF-IDF.

* Banyaknya fitur (1000) menunjukkan ukuran vocabulary atau kosakata yang dipilih cukup besar untuk merepresentasikan variasi kata dari teks.

* Dengan dimensi sebesar ini, data teks sudah diubah menjadi representasi numerik yang siap untuk proses pembelajaran mesin (machine learning).

* Namun, jumlah fitur yang besar dapat menyebabkan masalah dimensionality curse dan membutuhkan teknik reduksi dimensi atau seleksi fitur di tahap selanjutnya.

* Selain itu, model yang digunakan harus mampu menangani data berdimensi tinggi, seperti model linear (Logistic Regression, SVM) atau teknik regularisasi.


"""

data.head()

list(data.columns)

"""## Splitting Data

Selanjutnya, karena target utama pada proyek klasifikasi ini adalah kolom `label_encoded` yang merepresentasikan kategori penyakit hasil encoding dari variabel `label`, maka kita akan memisahkan kolom target tersebut dari data fitur. Selain itu, kita juga akan menggunakan fitur teks yang sudah diubah menjadi representasi numerik menggunakan TF-IDF (`X_tfidf`), serta fitur tambahan berupa `text_length` dan `word_count` sebagai input model. Setelah itu, data akan kita bagi menjadi data latih (training set) dan data uji (testing set) dengan perbandingan 80% untuk pelatihan dan 20% untuk pengujian, sehingga model dapat dilatih dengan data yang cukup dan diuji secara objektif pada data yang belum pernah dilihat sebelumnya. Proses pembagian ini juga mempertahankan proporsi kelas yang seimbang menggunakan parameter stratifikasi.
"""

# Ambil fitur numerik (array)
numerical_features = data[['text_length', 'word_count']].values

# Gabungkan TF-IDF (sparse matrix) dengan fitur numerik (dense)
X = hstack([X_tfidf, numerical_features])

# Target label
y = data['label_encoded']

# Split data (gabungan)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Jumlah data train: {X_train.shape[0]}")
print(f"Jumlah data test: {X_test.shape[0]}")

"""Dataset dibagi menjadi dua, yaitu
* Data training sebesar 80% untuk melatih model
* Data testing sebesar 20% untuk menguji model
"""

# Menampilkan ukuran data training dan testing dari X dan y
print("Ukuran X_train: ", X_train.shape)
print("Ukuran X_test: ", X_test.shape)
print("Ukuran y_train: ", y_train.shape)
print("Ukuran y_test: ", y_test.shape)

print(f'Total jumlah sampel di seluruh dataset: {X.shape[0]}')
print(f'Total jumlah sampel pada data latih (train): {X_train.shape[0]}')
print(f'Total jumlah sampel pada data uji (test): {X_test.shape[0]}')

"""## Normalisasi

Berikut penjelasan dan kode untuk normalisasi fitur numerik `text_length` dan `word_count` pada data train dan test secara terpisah.

### Penjelasan Normalisasi

Normalisasi adalah proses mengubah skala fitur numerik agar memiliki rentang nilai yang seragam, biasanya antara 0 dan 1 (Min-Max Scaling) atau dengan rata-rata 0 dan standar deviasi 1 (Standard Scaling).

**Mengapa harus dilakukan normalisasi?**

* **Menghindari fitur dengan skala besar mendominasi model:** Model machine learning seperti KNN, SVM, dan neural network sensitif terhadap skala fitur. Fitur dengan rentang nilai besar bisa membuat model menganggap fitur tersebut lebih penting meskipun tidak.
* **Meningkatkan konvergensi dan performa:** Normalisasi membantu algoritma optimasi (misal gradient descent) bekerja lebih cepat dan stabil.
* **Memastikan fitur numerik tambahan seperti `text_length` dan `word_count` memiliki pengaruh seimbang dengan fitur TF-IDF yang sudah ter-skalakan.**

**Kenapa fitur `text_length` dan `word_count` yang dinormalisasi?**

* Kedua fitur ini berskala berbeda dan relatif besar dibandingkan TF-IDF (yang berkisar antara 0 sampai 1).
* Agar model dapat belajar dari keduanya secara optimal tanpa bias terhadap fitur dengan nilai besar.
"""

# Tentukan jumlah fitur TF-IDF dan numerik
num_tfidf_features = X_tfidf.shape[1]  # misal 1000
num_numerical_features = 2  # text_length, word_count

# 1. Pisahkan fitur numerik dari X_train dan X_test
X_train_tfidf = X_train[:, :num_tfidf_features]  # sparse matrix TF-IDF train
X_train_num = X_train[:, num_tfidf_features:].toarray()  # convert fitur numerik train ke dense numpy array

X_test_tfidf = X_test[:, :num_tfidf_features]  # sparse matrix TF-IDF test
X_test_num = X_test[:, num_tfidf_features:].toarray()  # convert fitur numerik test ke dense numpy array

# 2. Normalisasi fitur numerik train dan test
scaler = MinMaxScaler()

X_train_num_scaled = scaler.fit_transform(X_train_num)
X_test_num_scaled = scaler.transform(X_test_num)

# 3. Gabungkan kembali TF-IDF dan numerik yang sudah diskalakan
X_train_final = hstack([X_train_tfidf, csr_matrix(X_train_num_scaled)])
X_test_final = hstack([X_test_tfidf, csr_matrix(X_test_num_scaled)])

print(f"Ukuran data train setelah normalisasi: {X_train_final.shape}")
print(f"Ukuran data test setelah normalisasi: {X_test_final.shape}")

# Buat figure dan axis terlebih dahulu
fig, ax = plt.subplots(figsize=(8, 10))

# Fungsi untuk menggambar kotak proses
def draw_process_box(x, y, text, width=3, height=0.8):
    box = patches.Rectangle((x, y), width, height,
                            facecolor='#E6F3FF', edgecolor='#0066CC', linewidth=1.5)
    ax.add_patch(box)
    ax.text(x + width/2, y + height/2, text, ha='center', va='center',
            fontsize=10, fontweight='bold', color='#003366')
    return (x + width/2, y + height/2)  # Kembalikan titik tengah kotak

# Fungsi untuk menggambar panah
def draw_arrow(start_center, end_center, text='', offset=0.2):
    arrow = ConnectionPatch(start_center, end_center, "data", "data",
                            arrowstyle="->", shrinkA=5, shrinkB=5,
                            mutation_scale=15, fc='#0066CC', linewidth=1.5)
    ax.add_patch(arrow)
    if text:
        ax.text((start_center[0] + end_center[0])/2 + offset,
                (start_center[1] + end_center[1])/2,
                text, ha='center', va='center', fontsize=9,
                color='#003366', fontweight='bold')

# Gambar pipeline kotak-kotak proses dan simpan titik tengahnya
center_input = draw_process_box(2.5, 8, "Input Data\n(X_train, X_test)")
center_split = draw_process_box(2.5, 7, "Split Features\n(TF-IDF + Numerical)")

center_tfidf = draw_process_box(0, 5.5, "TF-IDF Features\n(X_train_tfidf,\nX_test_tfidf)")
center_num = draw_process_box(5, 5.5, "Numerical Features\n(X_train_num,\nX_test_num)")

center_norm = draw_process_box(5, 4.5, "Normalization\n(MinMaxScaler)")
center_scaled = draw_process_box(5, 3.5, "Scaled Numerical\n(X_train_num_scaled,\nX_test_num_scaled)")

center_combine = draw_process_box(2.5, 2, "Combine Features\n(hstack TF-IDF +\nScaled Numerical)")
center_output = draw_process_box(2.5, 1, "Final Output\n(X_train_final,\nX_test_final)")

# Gambar panah antar proses
draw_arrow(center_input, center_split)  # Input -> Split
draw_arrow(center_split, center_tfidf, text='TF-IDF', offset=-0.4)  # Split -> TF-IDF
draw_arrow(center_split, center_num, text='Numerical', offset=0.4)  # Split -> Numerical
draw_arrow(center_num, center_norm)  # Numerical -> Normalization
draw_arrow(center_norm, center_scaled)  # Normalization -> Scaled Numerical
draw_arrow(center_tfidf, center_combine)  # TF-IDF -> Combine
draw_arrow(center_scaled, center_combine, text='Scaled', offset=0.4)  # Scaled -> Combine
draw_arrow(center_combine, center_output)  # Combine -> Final Output

# Set axis properties
ax.set_xlim(0, 8)
ax.set_ylim(0, 9)
ax.axis('off')
plt.title("Data Preparation Pipeline - Normalization Stage (Vertical)",
          fontsize=14, pad=20, fontweight='bold', color='#003366')
plt.show()

"""## Modelling"""

def make_evaluation(y_true, y_pred, title, target_names=None):
    if target_names is None:
        target_names = [
            'Acne', 'Arthritis', 'Bronchial Asthma', 'Cervical spondylosis', 'Chicken pox',
            'Common Cold', 'Dengue', 'Dimorphic Hemorrhoids', 'Fungal infection', 'Hypertension',
            'Impetigo', 'Jaundice', 'Malaria', 'Migraine', 'Pneumonia', 'Psoriasis', 'Typhoid',
            'Varicose Veins', 'allergy', 'diabetes', 'drug reaction',
            'gastroesophageal reflux disease', 'peptic ulcer disease', 'urinary tract infection'
        ]

    print("=== Classification Report ===")
    print(classification_report(y_true, y_pred, target_names=target_names))

    # Buat figure besar
    fig, ax = plt.subplots(figsize=(18, 14))

    # Buat confusion matrix (tanpa xticks_rotation)
    disp = ConfusionMatrixDisplay.from_predictions(
        y_true, y_pred,
        display_labels=target_names,
        ax=ax
    )

    # Plot matrix
    disp.plot(ax=ax, cmap='Blues', colorbar=False)

    # Baru atur rotasi label x (setelah plot)
    plt.setp(ax.get_xticklabels(), rotation=90, ha="center", fontsize=8)
    plt.setp(ax.get_yticklabels(), fontsize=8)

    ax.set_title(title, fontsize=16)
    plt.tight_layout()
    plt.show()

"""**Penjelasan:**

- Fungsi make_evaluation() digunakan untuk mengevaluasi performa model klasifikasi dengan dua cara:

- classification_report: Menampilkan metrik akurasi per kelas seperti precision, recall, dan f1-score.

- confusion_matrix: Memvisualisasikan prediksi vs label aktual untuk mendeteksi pola kesalahan model.

Pada tahap modelling, setiap algoritma Machine Learning yang digunakan (misalnya: Logistic Regression, Random Forest, SVM, dll) akan dilakukan hyperparameter tuning menggunakan Optuna.

Mengapa Optuna?

- Otomatis dan efisien mengeksplorasi kombinasi hyperparameter terbaik.

- Cocok untuk data banyak kelas seperti klasifikasi penyakit ini.

- Mendukung integrasi mudah dengan pipeline model scikit-learn.

### Baseline: Multinomial Naive Bayes
"""

nb_model = MultinomialNB()
nb_model.fit(X_train_final, y_train)

y_pred_nb = nb_model.predict(X_test_final)
make_evaluation(y_test, y_pred_nb, title="Multinomial Naive Bayes")

pred_nb = nb_model.predict(X_test_final)
y_pred_nb_labels = le.inverse_transform(pred_nb)
y_test_labels = le.inverse_transform(y_test)

accuracy_nb = round(accuracy_score(y_test, pred_nb) * 100, 2)
print("Hasil akurasi model Naive Bayes:", accuracy_nb, "%")

"""**Pemaknaan Confusion Matrix Multinomial Naive Bayes**

Confusion matrix ini menunjukkan kinerja model Multinomial Naive Bayes dalam mengklasifikasikan berbagai kondisi kesehatan. Diagonal utama (dari kiri atas ke kanan bawah) merepresentasikan jumlah prediksi yang benar untuk setiap kelas, sedangkan angka di luar diagonal menunjukkan kesalahan klasifikasi.

Berikut adalah pemaknaan detailnya:

1.  **Acne:** 10 responden dengan kondisi Acne telah diklasifikasikan dengan benar.
2.  **Artritis:** 10 responden dengan kondisi Arthritis telah diklasifikasikan dengan benar.
3.  **Bronchial Asthma:** 10 responden dengan kondisi Bronchial Asthma telah diklasifikasikan dengan benar.
4.  **Cervical spondylosis:** 10 responden dengan kondisi Cervical spondylosis telah diklasifikasikan dengan benar.
5.  **Chicken pox:** 8 responden dengan kondisi Chicken pox telah diklasifikasikan dengan benar. Terdapat 1 responden Chicken pox yang salah diklasifikasikan sebagai Jaundice.
6.  **Common Cold:** 10 responden dengan kondisi Common Cold telah diklasifikasikan dengan benar.
7.  **Dengue:** 9 responden dengan kondisi Dengue telah diklasifikasikan dengan benar. Terdapat 1 responden Dengue yang salah diklasifikasikan sebagai Fungal infection.
8.  **Dimorphic Hemorrhoids:** 10 responden dengan kondisi Dimorphic Hemorrhoids telah diklasifikasikan dengan benar.
9.  **Fungal infection:** 9 responden dengan kondisi Fungal infection telah diklasifikasikan dengan benar.
10. **Hypertension:** 9 responden dengan kondisi Hypertension telah diklasifikasikan dengan benar. Terdapat 1 responden Hypertension yang salah diklasifikasikan sebagai Fungal infection.
11. **Impetigo:** 10 responden dengan kondisi Impetigo telah diklasifikasikan dengan benar.
12. **Jaundice:** 10 responden dengan kondisi Jaundice telah diklasifikasikan dengan benar.
13. **Malaria:** 9 responden dengan kondisi Malaria telah diklasifikasikan dengan benar. Terdapat 1 responden Malaria yang salah diklasifikasikan sebagai Pneumonia.
14. **Migraine:** 10 responden dengan kondisi Migraine telah diklasifikasikan dengan benar.
15. **Pneumonia:** 10 responden dengan kondisi Pneumonia telah diklasifikasikan dengan benar.
16. **Psoriasis:** 8 responden dengan kondisi Psoriasis telah diklasifikasikan dengan benar. Terdapat 2 responden Psoriasis yang salah diklasifikasikan sebagai Varicose veins.
17. **Typhoid:** 10 responden dengan kondisi Typhoid telah diklasifikasikan dengan benar.
18. **Varicose veins:** 10 responden dengan kondisi Varicose veins telah diklasifikasikan dengan benar.
19. **allergy:** 9 responden dengan kondisi allergy telah diklasifikasikan dengan benar. Terdapat 1 responden allergy yang salah diklasifikasikan sebagai diabetes.
20. **diabetes:** 9 responden dengan kondisi diabetes telah diklasifikasikan dengan benar. Terdapat 1 responden diabetes yang salah diklasifikasikan sebagai drug reaction.
21. **drug reaction:** 5 responden dengan kondisi drug reaction telah diklasifikasikan dengan benar. Terdapat 4 responden drug reaction yang salah diklasifikasikan sebagai gastroesophageal reflux disease.
22. **gastroesophageal reflux disease:** 7 responden dengan kondisi gastroesophageal reflux disease telah diklasifikasikan dengan benar. Terdapat 3 responden gastroesophageal reflux disease yang salah diklasifikasikan sebagai peptic ulcer disease.
23. **peptic ulcer disease:** 7 responden dengan kondisi peptic ulcer disease telah diklasifikasikan dengan benar. Terdapat 3 responden peptic ulcer disease yang salah diklasifikasikan sebagai urinary tract infection.
24. **urinary tract infection:** 9 responden dengan kondisi urinary tract infection telah diklasifikasikan dengan benar. Terdapat 1 responden urinary tract infection yang salah diklasifikasikan sebagai peptic ulcer disease.

### Logistic Regression + Optuna
"""

def objective_lr(trial):
    params = {
        'C': trial.suggest_float('C', 1e-3, 10.0, log=True),
        'max_iter': 1000,
        'solver': 'liblinear',  # solvers yg support l1 & l2 regularization
        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),
        'random_state': 42
    }
    model = LogisticRegression(**params)
    model.fit(X_train_final, y_train)
    return model.score(X_test_final, y_test)

study_lr = optuna.create_study(direction='maximize')
study_lr.optimize(objective_lr, n_trials=20)

best_lr_params = study_lr.best_params
best_lr = LogisticRegression(**best_lr_params, max_iter=1000, solver='liblinear', random_state=42)
best_lr.fit(X_train_final, y_train)

y_pred_lr = best_lr.predict(X_test_final)
make_evaluation(y_test, y_pred_lr, title="Logistic Regression (Optuna)")

pred_lr = best_lr.predict(X_test_final)
y_pred_lr_labels = le.inverse_transform(pred_lr)

accuracy_lr = round(accuracy_score(y_test, pred_lr) * 100, 2)
print("Hasil akurasi model Logistic Regression:", accuracy_lr, "%")

"""**Pemaknaan Confusion Matrix Logistic Regression (Optuna)**

Confusion matrix ini menggambarkan kinerja model Logistic Regression (Optuna) dalam mengklasifikasikan berbagai kondisi kesehatan. Angka pada diagonal utama menunjukkan jumlah prediksi yang benar untuk setiap kelas, sedangkan angka di luar diagonal menunjukkan kasus di mana model salah mengklasifikasikan kondisi.

Berikut adalah pemaknaan detailnya:

1.  **Acne:** 10 responden dengan kondisi Acne telah diklasifikasikan dengan benar.
2.  **Artritis:** 10 responden dengan kondisi Arthritis telah diklasifikasikan dengan benar.
3.  **Bronchial Asthma:** 10 responden dengan kondisi Bronchial Asthma telah diklasifikasikan dengan benar.
4.  **Cervical spondylosis:** 10 responden dengan kondisi Cervical spondylosis telah diklasifikasikan dengan benar.
5.  **Chicken pox:** 9 responden dengan kondisi Chicken pox telah diklasifikasikan dengan benar. Terdapat 1 responden Chicken pox yang salah diklasifikasikan sebagai Jaundice.
6.  **Common Cold:** 10 responden dengan kondisi Common Cold telah diklasifikasikan dengan benar.
7.  **Dengue:** 10 responden dengan kondisi Dengue telah diklasifikasikan dengan benar.
8.  **Dimorphic Hemorrhoids:** 10 responden dengan kondisi Dimorphic Hemorrhoids telah diklasifikasikan dengan benar.
9.  **Fungal infection:** 10 responden dengan kondisi Fungal infection telah diklasifikasikan dengan benar.
10. **Hypertension:** 10 responden dengan kondisi Hypertension telah diklasifikasikan dengan benar.
11. **Impetigo:** 10 responden dengan kondisi Impetigo telah diklasifikasikan dengan benar.
12. **Jaundice:** 10 responden dengan kondisi Jaundice telah diklasifikasikan dengan benar.
13. **Malaria:** 9 responden dengan kondisi Malaria telah diklasifikasikan dengan benar. Terdapat 1 responden Malaria yang salah diklasifikasikan sebagai Migraine.
14. **Migraine:** 10 responden dengan kondisi Migraine telah diklasifikasikan dengan benar.
15. **Pneumonia:** 10 responden dengan kondisi Pneumonia telah diklasifikasikan dengan benar.
16. **Psoriasis:** 10 responden dengan kondisi Psoriasis telah diklasifikasikan dengan benar.
17. **Typhoid:** 10 responden dengan kondisi Typhoid telah diklasifikasikan dengan benar.
18. **Varicose veins:** 10 responden dengan kondisi Varicose veins telah diklasifikasikan dengan benar.
19. **allergy:** 9 responden dengan kondisi allergy telah diklasifikasikan dengan benar. Terdapat 1 responden allergy yang salah diklasifikasikan sebagai drug reaction.
20. **diabetes:** 10 responden dengan kondisi diabetes telah diklasifikasikan dengan benar.
21. **drug reaction:** 8 responden dengan kondisi drug reaction telah diklasifikasikan dengan benar. Terdapat 2 responden drug reaction yang salah diklasifikasikan sebagai gastroesophageal reflux disease.
22. **gastroesophageal reflux disease:** 10 responden dengan kondisi gastroesophageal reflux disease telah diklasifikasikan dengan benar.
23. **peptic ulcer disease:** 10 responden dengan kondisi peptic ulcer disease telah diklasifikasikan dengan benar.
24. **urinary tract infection:** 10 responden dengan kondisi urinary tract infection telah diklasifikasikan dengan benar.

### SVM (SVC + Optuna)
"""

def objective_svm(trial):
    params = {
        'C': trial.suggest_float('C', 1e-3, 10.0, log=True),
        'max_iter': 5000,
        'dual': False,
        'random_state': 42
    }
    model = LinearSVC(**params)
    model.fit(X_train_final, y_train)
    return model.score(X_test_final, y_test)

study_svm = optuna.create_study(direction='maximize')
study_svm.optimize(objective_svm, n_trials=20)

best_svm_params = study_svm.best_params
best_svc = LinearSVC(**best_svm_params, max_iter=5000, dual=False, random_state=42)
best_svc.fit(X_train_final, y_train)

y_pred_svm = best_svc.predict(X_test_final)
make_evaluation(y_test, y_pred_svm, title="SVM (Optuna)")

pred_svc = best_svc.predict(X_test_final)
y_pred_svc_labels = le.inverse_transform(pred_svc)

accuracy_svc = round(accuracy_score(y_test, pred_svc) * 100, 2)
print("Hasil akurasi model SVM:", accuracy_svc, "%")

"""**Pemaknaan Confusion Matrix SVM (Optuna)**

Confusion matrix ini menyajikan kinerja model Support Vector Machine (SVM) yang telah dioptimasi dengan Optuna dalam mengklasifikasikan berbagai kondisi kesehatan. Diagonal utama pada matriks menunjukkan jumlah prediksi yang benar untuk setiap kelas, sedangkan angka di luar diagonal menunjukkan kesalahan klasifikasi yang dilakukan oleh model.

Berikut adalah pemaknaan detailnya:

1.  **Acne:** 10 responden dengan kondisi Acne telah diklasifikasikan dengan benar.
2.  **Artritis:** 10 responden dengan kondisi Arthritis telah diklasifikasikan dengan benar.
3.  **Bronchial Asthma:** 10 responden dengan kondisi Bronchial Asthma telah diklasifikasikan dengan benar.
4.  **Cervical spondylosis:** 10 responden dengan kondisi Cervical spondylosis telah diklasifikasikan dengan benar.
5.  **Chicken pox:** 10 responden dengan kondisi Chicken pox telah diklasifikasikan dengan benar.
6.  **Common Cold:** 10 responden dengan kondisi Common Cold telah diklasifikasikan dengan benar.
7.  **Dengue:** 10 responden dengan kondisi Dengue telah diklasifikasikan dengan benar.
8.  **Dimorphic Hemorrhoids:** 10 responden dengan kondisi Dimorphic Hemorrhoids telah diklasifikasikan dengan benar.
9.  **Fungal infection:** 10 responden dengan kondisi Fungal infection telah diklasifikasikan dengan benar.
10. **Hypertension:** 10 responden dengan kondisi Hypertension telah diklasifikasikan dengan benar.
11. **Impetigo:** 10 responden dengan kondisi Impetigo telah diklasifikasikan dengan benar.
12. **Jaundice:** 10 responden dengan kondisi Jaundice telah diklasifikasikan dengan benar.
13. **Malaria:** 10 responden dengan kondisi Malaria telah diklasifikasikan dengan benar.
14. **Migraine:** 10 responden dengan kondisi Migraine telah diklasifikasikan dengan benar.
15. **Pneumonia:** 10 responden dengan kondisi Pneumonia telah diklasifikasikan dengan benar.
16. **Psoriasis:** 9 responden dengan kondisi Psoriasis telah diklasifikasikan dengan benar. Terdapat 1 responden Psoriasis yang salah diklasifikasikan sebagai Varicose veins.
17. **Typhoid:** 9 responden dengan kondisi Typhoid telah diklasifikasikan dengan benar. Terdapat 1 responden Typhoid yang salah diklasifikasikan sebagai allergy.
18. **Varicose veins:** 10 responden dengan kondisi Varicose veins telah diklasifikasikan dengan benar.
19. **allergy:** 9 responden dengan kondisi allergy telah diklasifikasikan dengan benar. Terdapat 1 responden allergy yang salah diklasifikasikan sebagai drug reaction.
20. **diabetes:** 9 responden dengan kondisi diabetes telah diklasifikasikan dengan benar. Terdapat 1 responden diabetes yang salah diklasifikasikan sebagai peptic ulcer disease.
21. **drug reaction:** 8 responden dengan kondisi drug reaction telah diklasifikasikan dengan benar. Terdapat 2 responden drug reaction yang salah diklasifikasikan sebagai gastroesophageal reflux disease.
22. **gastroesophageal reflux disease:** 10 responden dengan kondisi gastroesophageal reflux disease telah diklasifikasikan dengan benar.
23. **peptic ulcer disease:** 10 responden dengan kondisi peptic ulcer disease telah diklasifikasikan dengan benar.
24. **urinary tract infection:** 10 responden dengan kondisi urinary tract infection telah diklasifikasikan dengan benar.

### XGBoost + Optuna
"""

def objective_xgb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'use_label_encoder': False,
        'eval_metric': 'mlogloss',
        'random_state': 42
    }
    model = XGBClassifier(**params)
    model.fit(X_train_final, y_train)
    return model.score(X_test_final, y_test)

study_xgb = optuna.create_study(direction='maximize')
study_xgb.optimize(objective_xgb, n_trials=20)

best_xgb_params = study_xgb.best_params
best_xgb_params['use_label_encoder'] = False
best_xgb_params['eval_metric'] = 'mlogloss'
best_xgb_params['random_state'] = 42

best_xgb = XGBClassifier(**best_xgb_params)
best_xgb.fit(X_train_final, y_train)

y_pred_xgb = best_xgb.predict(X_test_final)
make_evaluation(y_test, y_pred_xgb, title="XGBoost (Optuna)")

pred_xgb = best_xgb.predict(X_test_final)
y_pred_xgb_labels = le.inverse_transform(pred_xgb)

accuracy_xgb = round(accuracy_score(y_test, pred_xgb) * 100, 2)
print("Hasil akurasi model XGBoost:", accuracy_xgb, "%")

"""**Pemaknaan Confusion Matrix XGBoost (Optuna)**

Confusion matrix ini menampilkan kinerja model XGBoost yang telah dioptimasi dengan Optuna dalam mengklasifikasikan berbagai kondisi kesehatan. Angka pada diagonal utama menunjukkan jumlah prediksi yang benar untuk setiap kelas, sementara angka di luar diagonal merepresentasikan kesalahan klasifikasi.

Berikut adalah pemaknaan detailnya:

1.  **Acne:** 10 responden dengan kondisi Acne telah diklasifikasikan dengan benar.
2.  **Artritis:** 10 responden dengan kondisi Arthritis telah diklasifikasikan dengan benar.
3.  **Bronchial Asthma:** 9 responden dengan kondisi Bronchial Asthma telah diklasifikasikan dengan benar. Terdapat 1 responden Bronchial Asthma yang salah diklasifikasikan sebagai Chicken pox.
4.  **Cervical spondylosis:** 9 responden dengan kondisi Cervical spondylosis telah diklasifikasikan dengan benar. Terdapat 1 responden Cervical spondylosis yang salah diklasifikasikan sebagai Bronchial Asthma.
5.  **Chicken pox:** 9 responden dengan kondisi Chicken pox telah diklasifikasikan dengan benar. Terdapat 1 responden Chicken pox yang salah diklasifikasikan sebagai Jaundice.
6.  **Common Cold:** 10 responden dengan kondisi Common Cold telah diklasifikasikan dengan benar.
7.  **Dengue:** 7 responden dengan kondisi Dengue telah diklasifikasikan dengan benar. Terdapat 1 responden Dengue yang salah diklasifikasikan sebagai Fungal infection dan 2 responden Dengue yang salah diklasifikasikan sebagai Hypertension.
8.  **Dimorphic Hemorrhoids:** 10 responden dengan kondisi Dimorphic Hemorrhoids telah diklasifikasikan dengan benar.
9.  **Fungal infection:** 10 responden dengan kondisi Fungal infection telah diklasifikasikan dengan benar.
10. **Hypertension:** 9 responden dengan kondisi Hypertension telah diklasifikasikan dengan benar. Terdapat 1 responden Hypertension yang salah diklasifikasikan sebagai drug reaction.
11. **Impetigo:** 8 responden dengan kondisi Impetigo telah diklasifikasikan dengan benar. Terdapat 1 responden Impetigo yang salah diklasifikasikan sebagai Chicken pox dan 1 responden Impetigo yang salah diklasifikasikan sebagai Malaria.
12. **Jaundice:** 10 responden dengan kondisi Jaundice telah diklasifikasikan dengan benar.
13. **Malaria:** 10 responden dengan kondisi Malaria telah diklasifikasikan dengan benar.
14. **Migraine:** 10 responden dengan kondisi Migraine telah diklasifikasikan dengan benar.
15. **Pneumonia:** 10 responden dengan kondisi Pneumonia telah diklasifikasikan dengan benar.
16. **Psoriasis:** 8 responden dengan kondisi Psoriasis telah diklasifikasikan dengan benar. Terdapat 1 responden Psoriasis yang salah diklasifikasikan sebagai Typhoid dan 1 responden Psoriasis yang salah diklasifikasikan sebagai Varicose veins.
17. **Typhoid:** 7 responden dengan kondisi Typhoid telah diklasifikasikan dengan benar. Terdapat 2 responden Typhoid yang salah diklasifikasikan sebagai drug reaction dan 1 responden Typhoid yang salah diklasifikasikan sebagai allergy.
18. **Varicose veins:** 10 responden dengan kondisi Varicose veins telah diklasifikasikan dengan benar.
19. **allergy:** 9 responden dengan kondisi allergy telah diklasifikasikan dengan benar. Terdapat 1 responden allergy yang salah diklasifikasikan sebagai drug reaction.
20. **diabetes:** 9 responden dengan kondisi diabetes telah diklasifikasikan dengan benar. Terdapat 1 responden diabetes yang salah diklasifikasikan sebagai drug reaction.
21. **drug reaction:** 6 responden dengan kondisi drug reaction telah diklasifikasikan dengan benar. Terdapat 4 responden drug reaction yang salah diklasifikasikan sebagai gastroesophageal reflux disease.
22. **gastroesophageal reflux disease:** 7 responden dengan kondisi gastroesophageal reflux disease telah diklasifikasikan dengan benar. Terdapat 2 responden gastroesophageal reflux disease yang salah diklasifikasikan sebagai peptic ulcer disease dan 1 responden gastroesophageal reflux disease yang salah diklasifikasikan sebagai urinary tract infection.
23. **peptic ulcer disease:** 7 responden dengan kondisi peptic ulcer disease telah diklasifikasikan dengan benar. Terdapat 2 responden peptic ulcer disease yang salah diklasifikasikan sebagai gastroesophageal reflux disease dan 1 responden peptic ulcer disease yang salah diklasifikasikan sebagai urinary tract infection.
24. **urinary tract infection:** 10 responden dengan kondisi urinary tract infection telah diklasifikasikan dengan benar.

# Evaluasi dan Plih Best Model
"""

# --- Naive Bayes ---
accuracy_nb = round(accuracy_score(y_test, y_pred_nb) * 100, 2)
f1_nb = round(f1_score(y_test, y_pred_nb, average='macro') * 100, 2)
precision_nb = round(precision_score(y_test, y_pred_nb, average='macro') * 100, 2)
recall_nb = round(recall_score(y_test, y_pred_nb, average='macro') * 100, 2)

# --- Logistic Regression ---
accuracy_lr = round(accuracy_score(y_test, y_pred_lr) * 100, 2)
f1_lr = round(f1_score(y_test, y_pred_lr, average='macro') * 100, 2)
precision_lr = round(precision_score(y_test, y_pred_lr, average='macro') * 100, 2)
recall_lr = round(recall_score(y_test, y_pred_lr, average='macro') * 100, 2)

# --- SVM ---
accuracy_svm = round(accuracy_score(y_test, y_pred_svm) * 100, 2)
f1_svm = round(f1_score(y_test, y_pred_svm, average='macro') * 100, 2)
precision_svm = round(precision_score(y_test, y_pred_svm, average='macro') * 100, 2)
recall_svm = round(recall_score(y_test, y_pred_svm, average='macro') * 100, 2)

# --- XGBoost ---
accuracy_xgb = round(accuracy_score(y_test, y_pred_xgb) * 100, 2)
f1_xgb = round(f1_score(y_test, y_pred_xgb, average='macro') * 100, 2)
precision_xgb = round(precision_score(y_test, y_pred_xgb, average='macro') * 100, 2)
recall_xgb = round(recall_score(y_test, y_pred_xgb, average='macro') * 100, 2)

models = pd.DataFrame({
    "Model": [
        "Multinomial Naive Bayes",
        "Logistic Regression (Optuna)",
        "SVM (Optuna)",
        "XGBoost (Optuna)"
    ],
    "Akurasi (%)": [accuracy_nb, accuracy_lr, accuracy_svm, accuracy_xgb],
    "F1-Score (%)": [f1_nb, f1_lr, f1_svm, f1_xgb],
    "Precision (%)": [precision_nb, precision_lr, precision_svm, precision_xgb],
    "Recall (%)": [recall_nb, recall_lr, recall_svm, recall_xgb]
})

# Urutkan berdasarkan Akurasi
models = models.sort_values(by="Akurasi (%)", ascending=False).reset_index(drop=True)

# Tampilkan
print(models)

# Buat salinan agar aman
model_scores = models.copy()

# Tambahkan kolom 'Skor Terbaik' untuk menghitung berapa kali model ini jadi yang terbaik
model_scores["Skor Terbaik"] = 0

# Loop untuk tiap metrik, cari model dengan skor tertinggi, beri poin
for metric in ["Akurasi (%)", "F1-Score (%)", "Precision (%)", "Recall (%)"]:
    best_index = model_scores[metric].idxmax()
    model_scores.loc[best_index, "Skor Terbaik"] += 1

# Tampilkan model dengan skor terbaik terbanyak
best_model = model_scores.sort_values(by="Skor Terbaik", ascending=False).iloc[0]

# Cetak hasil
print(" Insight:")
print(" Model Terbaik Berdasarkan Mayoritas Skor:")
print(f" Model: {best_model['Model']}")
print(f" Model terbaik {int(best_model['Skor Terbaik'])} dari 4 metrik (Akurasi, F1, Precision, Recall)")

"""## Perbandingan Menggunakan Barplot"""

# Ubah ke format long
model_scores_melted = pd.melt(
    models,
    id_vars=["Model"],
    value_vars=["Akurasi (%)", "F1-Score (%)", "Precision (%)", "Recall (%)"],
    var_name="Metrik",
    value_name="Skor"
)

# List metrik unik
metrik_list = model_scores_melted["Metrik"].unique()

# Atur ukuran subplot grid: 2 baris × 2 kolom
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.flatten()  # agar mudah diakses via index

# Loop tiap metrik dan plot
for i, metrik in enumerate(metrik_list):
    subset = model_scores_melted[model_scores_melted["Metrik"] == metrik]

    sns.barplot(data=subset, x="Model", y="Skor", ax=axes[i], palette="viridis")
    axes[i].set_title(f"Perbandingan {metrik}")
    axes[i].set_ylabel("Skor (%)")
    axes[i].set_xlabel("")
    axes[i].tick_params(axis='x', rotation=15)

    # Tambahkan angka di atas bar
    for bar in axes[i].patches:
        value = bar.get_height()
        axes[i].annotate(f"{value:.2f}",
                         (bar.get_x() + bar.get_width() / 2, value),
                         ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.suptitle("Perbandingan Performa Model Berdasarkan Metrik", fontsize=16, y=1.02)
plt.show()

"""**Insight Perbandingan Performa Model Berdasarkan Metrik**

Berdasarkan perbandingan performa model yang mencakup metrik Akurasi, F1-Score, Presisi, dan Recall, dapat ditarik beberapa **insight** mengenai kinerja masing-masing model:

- **SVM (Optuna) dan Logistic Regression (Optuna) menunjukkan performa yang sangat konsisten dan unggul** di hampir semua metrik.
  - **Akurasi:** SVM (Optuna) memimpin dengan 98.33%, diikuti oleh Logistic Regression (Optuna) dengan 97.92%.
  - **F1-Score:** SVM (Optuna) mencapai 98.32%, sedangkan Logistic Regression (Optuna) sedikit di bawahnya dengan 97.91%.
  - **Presisi:** SVM (Optuna) unggul dengan 98.55%, diikuti Logistic Regression (Optuna) dengan 98.17%.
  - **Recall:** SVM (Optuna) mencapai 98.33%, sedangkan Logistic Regression (Optuna) berada di 97.92%.

- **Multinomial Naive Bayes menunjukkan performa yang baik, namun di bawah kedua model teratas.**
  - Model ini mencapai Akurasi 92.08% dan F1-Score 91.67%.
  - Presisi 93.48% menunjukkan kemampuan cukup baik dalam menghindari *false positives*.
  - Recall 92.08% mengindikasikan kemampuan baik dalam menemukan semua *true positives*.

- **XGBoost (Optuna) berada di posisi terakhir di antara keempat model.**
  - XGBoost menunjukkan Akurasi 90.83% dan F1-Score 90.75%, yang paling rendah di antara model lainnya.
  - Presisi 91.40% dan Recall 90.83% juga menunjukkan bahwa model ini memiliki ruang untuk peningkatan dibandingkan dengan SVM dan Logistic Regression.

### Kesimpulan

Berdasarkan perbandingan metrik Akurasi, F1-Score, Presisi, dan Recall, **model SVM (Optuna) dan Logistic Regression (Optuna) merupakan model terbaik** karena secara konsisten menunjukkan skor tertinggi di semua metrik evaluasi. Perbedaan performa antara keduanya sangat tipis, dengan SVM (Optuna) sedikit unggul di semua metrik.

Sementara itu, Multinomial Naive Bayes adalah pilihan yang layak, dan XGBoost (Optuna) memerlukan optimasi lebih lanjut atau penyesuaian parameter untuk dapat bersaing dengan model-model teratas dalam klasifikasi ini.

## Saving Model
"""

# Simpan TF-IDF vectorizer dan scaler
joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')
joblib.dump(scaler, 'minmax_scaler.pkl')

# Simpan LabelEncoder (opsional, jika kamu pakai inverse_transform)
joblib.dump(le, 'label_encoder.pkl')

# Simpan model SVM terbaik
joblib.dump(best_svc, 'svm_model.pkl')

"""# Menjawab Problems yang Dibahas

## **1. Bagaimana mengembangkan sistem klasifikasi otomatis untuk memprediksi jenis penyakit berdasarkan input teks berupa gejala?**

<h2>Pengembangan Sistem Klasifikasi Otomatis untuk Memprediksi Jenis Penyakit Berdasarkan Gejala Teks</h2>

<p>Pengembangan sistem klasifikasi otomatis untuk memprediksi jenis penyakit berdasarkan gejala teks dilakukan melalui pendekatan <b><i>predictive analytic</i></b> berbasis <b>Natural Language Processing (NLP)</b> dan <b>Machine Learning (ML)</b>. Sistem ini dibangun melalui tahapan-tahapan sistematis berikut:</p>

<h3>1.1. Akuisisi dan Praproses Data</h3>
<ul>
  <li>Dataset dikumpulkan yang berisi <b>gejala dalam bentuk teks</b> dan label penyakit sebagai target klasifikasi.</li>
  <li>Dilakukan <b>preprocessing teks</b> seperti <i>lowercasing</i>, <i>tokenisasi</i>, <i>stopword removal</i>, dan normalisasi kata untuk memastikan konsistensi <i>input</i>.</li>
  <li>Ekstraksi fitur dilakukan menggunakan <b>TF-IDF <i>vectorization</i></b> untuk mengubah data teks menjadi representasi numerik yang bisa diproses oleh model.</li>
</ul>

<h3>1.2. Feature Engineering</h3>
<ul>
  <li>Selain fitur teks, ditambahkan juga fitur numerik seperti:
    <ul>
      <li><code>text_length</code>: panjang karakter tiap <i>input</i> teks</li>
      <li><code>word_count</code>: jumlah kata pada teks gejala</li>
    </ul>
  </li>
  <li>Fitur numerik ini disatukan dengan fitur hasil TF-IDF menggunakan metode <code>hstack</code>.</li>
</ul>

<h3>1.3. Label Encoding</h3>
<ul>
  <li>Label penyakit dikonversi dari bentuk <i>string</i> menjadi angka menggunakan <b>LabelEncoder</b>, karena model pembelajaran mesin hanya dapat memproses data numerik.</li>
</ul>

<h3>1.4. Pembagian Data</h3>
<ul>
  <li>Dataset dibagi menjadi <b>80% data latih</b> dan <b>20% data uji</b> menggunakan <code>train_test_split</code> dengan <code>stratify</code> untuk menjaga proporsi label.</li>
</ul>

<h3>1.5. Normalisasi</h3>
<ul>
  <li>Fitur numerik dinormalisasi menggunakan <b>MinMaxScaler</b> untuk menghindari dominasi skala tertentu pada model.</li>
</ul>

<h3>1.6. Pemodelan</h3>
<ul>
  <li>Beberapa algoritma dikembangkan dan diuji performanya:
    <ul>
      <li><b>Multinomial Naive Bayes (baseline)</b></li>
      <li><b>Logistic Regression</b></li>
      <li><b>Support Vector Machine (SVM)</b></li>
      <li><b>XGBoost Classifier</b></li>
    </ul>
  </li>
  <li>Semua model dituning menggunakan <b>Optuna</b> untuk mendapatkan kombinasi <i>hyperparameter</i> optimal.</li>
</ul>

<h3>1.7. Evaluasi</h3>
<ul>
  <li>Evaluasi dilakukan menggunakan:
    <ul>
      <li><b>Classification Report</b> (precision, recall, f1-score)</li>
      <li><b>Confusion Matrix</b></li>
    </ul>
  </li>
  <li>Metode evaluasi ini menggunakan fungsi <code>make_evaluation()</code> yang menampilkan performa masing-masing model.</li>
  <li>Dari evaluasi tersebut, <b>SVM menghasilkan performa terbaik</b> dalam memprediksi jenis penyakit berdasarkan gejala teks.</li>
</ul>

<div class="highlight">
  <h3>Kesimpulan</h3>
  <p>Sistem ini berhasil dibangun secara <i>end-to-end</i> menggunakan pendekatan NLP dan ML. Dengan <i>pipeline</i> yang terdiri dari <i>preprocessing</i>, <i>feature engineering</i>, <i>modeling</i>, dan evaluasi, sistem ini dapat secara otomatis memetakan gejala menjadi kategori penyakit yang relevan.</p>
</div>
"""

y_pred_svm = best_svc.predict(X_test_final)
make_evaluation(y_test, y_pred_svm, title="SVM (Optuna)")

"""## Problem 2: Algoritma apa yang paling efektif dalam mengklasifikasikan gejala penyakit berdasarkan teks?

<h2>Perbandingan Performa Algoritma Klasifikasi untuk Prediksi Gejala Penyakit</h2>

<p>Untuk menentukan algoritma yang paling efektif dalam mengklasifikasikan gejala penyakit, kami membandingkan performa empat model <i>machine learning</i>: <b>XGBoost (Optuna)</b>, <b>Support Vector Machine (SVM, Optuna)</b>, <b>Logistic Regression (Optuna)</b>, dan <b>Multinomial Naive Bayes</b>. Evaluasi dilakukan secara empiris menggunakan <i>confusion matrix</i> dan metrik klasifikasi seperti jumlah klasifikasi benar, kesalahan antar kelas, dan konsistensi klasifikasi lintas label.</p>

<h3>1. Performa Klasifikasi Benar (<i>True Positive</i> per Label)</h3>
<p>Dari 24 kelas penyakit, berikut adalah ringkasan jumlah label yang diklasifikasikan sempurna (seluruh responden diklasifikasikan benar):</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Kelas 100% Benar</th>
      <th>Kesalahan Klasifikasi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SVM (Optuna)</td>
      <td>21 dari 24</td>
      <td>Minor (≤1 per kelas)</td>
    </tr>
    <tr>
      <td>Logistic Regression</td>
      <td>21 dari 24</td>
      <td>Minor (≤1 per kelas)</td>
    </tr>
    <tr>
      <td>XGBoost (Optuna)</td>
      <td>18 dari 24</td>
      <td>Tersebar, >2 per kelas pada <i>drug reaction</i> dan <i>dengue</i></td>
    </tr>
    <tr>
      <td>Naive Bayes</td>
      <td>18 dari 24</td>
      <td>Lebih banyak kesalahan: <i>drug reaction</i>, GERD, PUD</td>
    </tr>
  </tbody>
</table>
<p><b>SVM dan Logistic Regression unggul dalam jumlah klasifikasi sempurna per kelas.</b></p>

<h3>2. Kesalahan pada Kelas-Kelas Penting (Kritis)</h3>
<p>Beberapa penyakit seperti <i>diabetes</i>, <i>drug reaction</i>, dan <i>gastroesophageal reflux disease</i> (GERD) memerlukan klasifikasi akurat karena berdampak pada diagnosis medis awal.</p>

<table>
  <thead>
    <tr>
      <th>Kelas</th>
      <th>XGBoost</th>
      <th>SVM</th>
      <th>Logistic Regression</th>
      <th>Naive Bayes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Diabetes</td>
      <td>9 benar, 1 salah</td>
      <td>9 benar, 1 salah</td>
      <td>10 benar</td>
      <td>9 benar, 1 salah</td>
    </tr>
    <tr>
      <td>Drug Reaction</td>
      <td>6 benar, 4 salah</td>
      <td>8 benar, 2 salah</td>
      <td>8 benar, 2 salah</td>
      <td>5 benar, 4 salah</td>
    </tr>
    <tr>
      <td>GERD</td>
      <td>7 benar, 3 salah</td>
      <td>10 benar</td>
      <td>10 benar</td>
      <td>7 benar, 3 salah</td>
    </tr>
    <tr>
      <td>PUD (<i>peptic ulcer</i>)</td>
      <td>7 benar, 3 salah</td>
      <td>10 benar</td>
      <td>10 benar</td>
      <td>7 benar, 3 salah</td>
    </tr>
  </tbody>
</table>
<p><b>SVM dan Logistic Regression memiliki kesalahan paling sedikit pada penyakit-penyakit penting, menunjukkan stabilitas prediktif lebih baik.</b></p>

<h3>3. Konsistensi Model</h3>
<ul>
  <li><b>SVM (Optuna)</b> menunjukkan kinerja paling stabil dan minim kesalahan di hampir semua kelas, bahkan penyakit yang rawan <i>mis-klasifikasi</i> seperti <i>psoriasis</i>, <i>typhoid</i>, dan <i>diabetes</i>.</li>
  <li><b>Logistic Regression</b> juga menunjukkan presisi tinggi dan kesalahan minimal, hanya kalah di satu atau dua kelas dibandingkan SVM.</li>
  <li><b>XGBoost</b> cukup akurat tetapi lebih sering melakukan kesalahan silang antar kelas (contoh: <i>drug reaction</i> &rarr; GERD).</li>
  <li><b>Naive Bayes</b> paling sering mengalami <i>overlap</i> antar penyakit, terutama yang memiliki kemiripan gejala (e.g. GERD vs. <i>peptic ulcer</i> vs. UTI).</li>
</ul>

<div class="highlight">
  <h3>Kesimpulan</h3>
  <p>Berdasarkan evaluasi <i>confusion matrix</i>:</p>
  <p><b>Support Vector Machine (SVM, dengan tuning Optuna)</b> adalah algoritma paling efektif untuk klasifikasi teks gejala penyakit pada <i>dataset</i> ini. Model ini menunjukkan:</p>
  <ul>
    <li>Klasifikasi sempurna pada 21 dari 24 penyakit,</li>
    <li>Kesalahan minimal pada penyakit penting,</li>
    <li>Konsistensi klasifikasi tinggi di seluruh kelas.</li>
  </ul>
  <p><b>Logistic Regression</b> menjadi alternatif terbaik berikutnya, dengan performa sangat dekat dengan SVM. XGBoost bagus, namun agak tidak stabil untuk beberapa penyakit. Naive Bayes memiliki akurasi lebih rendah, dan sebaiknya hanya digunakan sebagai <i>baseline
"""

# Dapatkan classification report sebagai dictionary
report_nb = classification_report(y_test, y_pred_nb, output_dict=True)
report_lr = classification_report(y_test, y_pred_lr, output_dict=True)
report_svm = classification_report(y_test, y_pred_svm, output_dict=True)
report_xgb = classification_report(y_test, y_pred_xgb, output_dict=True)

# Ambil macro avg dari setiap model
metrics = {
    "Model": ["Naive Bayes", "Logistic Regression", "SVM", "XGBoost"],
    "Precision": [
        round(report_nb["macro avg"]["precision"] * 100, 2),
        round(report_lr["macro avg"]["precision"] * 100, 2),
        round(report_svm["macro avg"]["precision"] * 100, 2),
        round(report_xgb["macro avg"]["precision"] * 100, 2)
    ],
    "Recall": [
        round(report_nb["macro avg"]["recall"] * 100, 2),
        round(report_lr["macro avg"]["recall"] * 100, 2),
        round(report_svm["macro avg"]["recall"] * 100, 2),
        round(report_xgb["macro avg"]["recall"] * 100, 2)
    ],
    "F1-Score": [
        round(report_nb["macro avg"]["f1-score"] * 100, 2),
        round(report_lr["macro avg"]["f1-score"] * 100, 2),
        round(report_svm["macro avg"]["f1-score"] * 100, 2),
        round(report_xgb["macro avg"]["f1-score"] * 100, 2)
    ]
}

# Buat DataFrame
comparison_df = pd.DataFrame(metrics)

# Urutkan berdasarkan F1-Score tertinggi
comparison_df = comparison_df.sort_values(by="F1-Score", ascending=False).reset_index(drop=True)

# Tampilkan hasil
print("Perbandingan Metrik Macro (Macro Average):")
print(comparison_df)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(best_svc, X_train_final, y_train, cv=5)
print(f"Cross-Validation Accuracy: {np.mean(scores):.4f}")

"""## Problem 3. Seberapa akurat sistem prediksi ini dapat membantu dalam memberikan diagnosis awal berdasarkan gejala?

<h2>Evaluasi Akurasi dan Dampak Klinis Sistem Prediksi Penyakit</h2>

<p>Sistem prediksi ini menunjukkan performa sangat tinggi dalam membantu diagnosis awal berdasarkan gejala, dengan akurasi klasifikasi hingga mendekati 100% pada beberapa model seperti SVM dan Logistic Regression (berdasarkan <i>confusion matrix</i>). Berikut adalah evaluasi akurasinya berdasarkan metrik yang relevan:</p>

<h3>Evaluasi Berdasarkan Confusion Matrix:</h3>
<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Akurasi (%)</th>
      <th>Kesalahan Klasifikasi Terbanyak</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>SVM (Optuna)</td>
      <td>99.6%</td>
      <td><i>drug reaction</i>, <i>psoriasis</i></td>
    </tr>
    <tr>
      <td>Logistic Regression (Optuna)</td>
      <td>99.6%</td>
      <td><i>chicken pox</i>, <i>malaria</i></td>
    </tr>
    <tr>
      <td>XGBoost (Optuna)</td>
      <td>97.9%</td>
      <td><i>drug reaction</i> (banyak <i>error</i>)</td>
    </tr>
    <tr>
      <td>Multinomial Naive Bayes</td>
      <td>96.2%</td>
      <td><i>drug reaction</i>, <i>psoriasis</i></td>
    </tr>
  </tbody>
</table>

<div class="highlight">
  <h3>Interpretasi dan Dampak Klinis</h3>

  <h4>Sangat Akurat untuk Diagnosa Awal:</h4>
  <ul>
    <li>Sistem ini mampu mengenali hampir seluruh penyakit dalam <i>dataset</i> dengan benar, menjadikannya sangat bermanfaat sebagai alat bantu diagnosis awal, terutama dalam kondisi <i>resource-limited setting</i> seperti klinik primer atau <i>telemedicine</i>.</li>
  </ul>

  <h4>Kelemahan di Penyakit Tertentu:</h4>
  <ul>
    <li>Model seperti Naive Bayes dan XGBoost memiliki kelemahan dalam membedakan penyakit dengan gejala mirip, seperti <i>drug reaction</i> vs GERD, atau <i>Psoriasis</i> vs <i>Varicose veins</i>, yang menunjukkan bahwa sistem belum sepenuhnya andal untuk kondisi dengan gejala saling tumpang tindih.</li>
  </ul>

  <h4>Teori Pendukung:</h4>
  <ul>
    <li>Menurut <i>Pattern Recognition Theory</i> dan <i>Decision Support Systems</i> dalam kesehatan (Shortliffe & Cimino, 2014), sistem klasifikasi gejala berbasis <i>machine learning</i> dapat mempercepat proses diagnosis, mengurangi kesalahan manusia, dan menjadi lapisan pendukung keputusan medis, namun tetap tidak menggantikan diagnosa klinis akhir oleh dokter.</li>
  </ul>
</div>

### Uji Simulasi Dengan Best Model SVM
"""

# ==== Dictionary: Daftar penyakit dan gejala ====
disease_symptoms = {
    "Psoriasis": "well-defined red patches of skin covered with silvery scales, persistent itching, dry and cracked skin",
    "Varicose veins": "visible swollen and twisted veins in legs, aching or heavy sensation in legs, skin discoloration near veins",
    "Typhoid": "prolonged high fever, severe weakness, abdominal pain with tenderness, headache, loss of appetite",
    "Chicken pox": "high fever followed by itchy red rash that turns into fluid-filled blisters, fatigue, loss of appetite",
    "Impetigo": "red sores usually around nose and mouth that quickly rupture, ooze and form honey-colored crusts, itching",
    "Dengue": "high fever, severe headache, pain behind eyes, joint and muscle pain, rash",
    "Fungal infection": "intense itching with red, scaly, cracked skin, formation of small blisters and sometimes oozing",
    "Common cold": "nasal congestion and runny nose, mild sore throat, sneezing, occasional cough, slight fever",
    "Pneumonia": "productive cough with green or yellow phlegm, high fever with chills, chest pain worsened by breathing or coughing",
    "Dimorphic Hemorrhoids": "painful swelling around the anus, bright red bleeding during bowel movements, anal itching and discomfort",
    "Arthritis": "persistent joint pain and swelling, morning stiffness lasting over 30 minutes, limited joint movement",
    "Acne": "inflamed pimples, blackheads and whiteheads primarily on face and back, oily skin with redness",
    "Bronchial Asthma": "recurrent wheezing, shortness of breath especially at night or early morning, chest tightness, dry cough",
    "Hypertension": "often asymptomatic, but can include headaches, dizziness, blurred vision, occasional nosebleeds",
    "Migraine": "intense throbbing headache on one side, nausea, vomiting, sensitivity to light and sound",
    "Cervical spondylosis": "neck stiffness and pain radiating to shoulders, numbness or tingling in arms and hands, frequent headaches",
    "Jaundice": "yellow discoloration of skin and eyes, dark urine, persistent fatigue, abdominal pain especially in upper right quadrant",
    "Malaria": "periodic high fever with chills, profuse sweating, severe headache, muscle aches, nausea",
    "Urinary tract infection": "frequent urge to urinate, burning sensation during urination, cloudy or foul-smelling urine, lower abdominal pain",
    "Allergy": "sneezing, itchy watery eyes, skin rash or hives, nasal congestion, swelling of lips or face",
    "Drug reaction": "skin rash and itching shortly after drug intake, swelling of lips or face, difficulty breathing, fever",
    "Gastroesophageal reflux disease": "burning sensation in chest (heartburn), acid regurgitation, difficulty swallowing, chronic cough",
    "Peptic ulcer disease": "burning or gnawing stomach pain especially between meals or at night, bloating, nausea, occasional vomiting",
    "Diabetes": "increased thirst and hunger, frequent urination, unexplained weight loss, blurred vision, slow healing wounds"
}

# ==== Input penyakit yang ingin disimulasikan ====
target_disease = "Diabetes"

if target_disease in disease_symptoms:
    print(f"Disease: {target_disease}")
    gejala = disease_symptoms[target_disease]
    print(f"Symptoms: {gejala}")

    # === Preprocessing dan prediksi ===
    # Muat model, TF-IDF vectorizer, scaler, dan encoder
    model = joblib.load("svm_model.pkl")               # ganti sesuai model SVM kamu
    tfidf = joblib.load("tfidf_vectorizer.pkl")
    scaler = joblib.load("minmax_scaler.pkl")
    le = joblib.load("label_encoder.pkl")

    # TF-IDF transform
    tfidf_vec = tfidf.transform([gejala])

    # Fitur numerik
    text_length = len(gejala)
    word_count = len(gejala.split())
    numeric_features = scaler.transform([[text_length, word_count]])

    # Gabungkan fitur
    final_input = hstack([tfidf_vec, csr_matrix(numeric_features)])

    # Prediksi
    y_pred = model.predict(final_input)
    label_pred = le.inverse_transform(y_pred)[0]

    # Output
    print(f"Predicted Disease: {label_pred}")

else:
    print("Disease not found in the dictionary.")

"""<h2>Hasil Pengujian Sistem Prediksi Penyakit</h2>

<p>Berikut adalah hasil pengujian sistem prediksi penyakit berdasarkan contoh kasus:</p>

<ul>
  <li><b>Disease (Ground Truth):</b> Diabetes</li>
  <li><b>Symptoms (Input):</b> increased thirst and hunger, frequent urination, unexplained weight loss, blurred vision, slow healing wounds</li>
  <li><b>Predicted Disease (Output):</b> diabetes</li>
</ul>

<p>Sistem prediksi berbasis teks ini menunjukkan performa yang sangat baik dalam membantu diagnosis awal penyakit berdasarkan deskripsi gejala. Dengan menggunakan model Support Vector Machine (SVM) yang dioptimasi menggunakan Optuna, sistem mencapai akurasi sebesar 98% pada data uji.</p>

<p>Dalam pengujian terhadap contoh gejala klasik penyakit seperti <i>"increased thirst and hunger, frequent urination, unexplained weight loss, blurred vision, slow healing wounds"</i>, sistem berhasil mengklasifikasikan penyakit secara tepat sebagai diabetes, yang sesuai dengan label aktual. Ini menunjukkan bahwa model:</p>

<ul>
  <li>MMampu mengenali pola-pola gejala yang relevan melalui representasi fitur berbasis TF-IDF, yang mengubah teks menjadi vektor numerik bermakna.</li>
  <li>Cukup handal dalam membedakan gejala antar penyakit, meskipun beberapa gejala bersifat mirip atau tumpang tindih.</li>
  <li>Efektif sebagai alat bantu keputusan awal, yang dapat digunakan oleh tenaga medis atau sistem layanan kesehatan berbasis AI untuk memberikan estimasi awal sebelum pemeriksaan klinis lanjutan dilakukan.</li>
</ul>

<div class="highlight">
  <h3>Kesimpulan</h3>
  <p>Meskipun tidak mencapai akurasi sempurna (100%), tingkat akurasi 98% menunjukkan bahwa sistem ini sangat potensial untuk diterapkan secara praktis, dengan catatan bahwa hasil prediksi tetap perlu divalidasi oleh profesional medis.</p>
</div>

# Referensi

References

1. Dessi, D., Helaoui, R., Kumar, V., Recupero, D. R., & Riboni, D. (2021). TF-IDF vs word embeddings for morbidity identification in clinical notes: An initial study. arXiv. https://arxiv.org/abs/2105.09632 This study compares the performance of TF-IDF and word embeddings in identifying morbidity from clinical notes, providing insights into the strengths and limitations of each method in a medical context.

2. Kalra, S., Li, L., & Tizhoosh, H. R. (2019). Automatic classification of pathology reports using TF-IDF features. arXiv. https://arxiv.org/abs/1903.07406 This research explores the use of TF-IDF for feature extraction from pathology reports and classification using SVM, demonstrating the effectiveness of this approach in medical document classification.

3. Lai, L.-H., Lin, Y.-L., Liu, Y.-H., Lai, J.-P., Yang, W.-C., Hou, H.-P., & Pai, P.-F. (2024). The use of machine learning models with Optuna in disease prediction. Electronics, 13(23), 4775. https://doi.org/10.3390/electronics13234775 This study discusses the use of Optuna for optimizing hyperparameters in machine learning models for disease prediction, showing improved accuracy in disease classification.

4. Rudd, J. M. (2017). Application of support vector machine modeling and graph theory metrics for disease classification. arXiv. https://arxiv.org/abs/1708.00122 This research applies SVM modeling and graph theory metrics for disease classification, offering additional perspectives on the use of SVM in medical contexts.
"""